[{"path":"http://osparcomm.github.io/HARSAT/CONTRIBUTING.html","id":null,"dir":"","previous_headings":"","what":"Contributor’s Guide","title":"Contributor’s Guide","text":"document help set access main repository harsat code, help contribute code.","code":""},{"path":"http://osparcomm.github.io/HARSAT/CONTRIBUTING.html","id":"summary","dir":"","previous_headings":"","what":"Summary","title":"Contributor’s Guide","text":"Main repository Github: https://github.com/osparcomm/HARSAT Repository currently private – access permissions, contact Chris Moulton OSPAR team, ones administer repository Github. need access read code contribute. Web documentation Github Pages: https://osparcomm.github.io/HARSAT/","code":""},{"path":"http://osparcomm.github.io/HARSAT/CONTRIBUTING.html","id":"packaging","dir":"","previous_headings":"","what":"Packaging","title":"Contributor’s Guide","text":"aim make harsat code work R package. going distributed CRAN near future least. Instead, can installed directly Github. install latest development version, use remotes package: install harsat code dependencies. Note: development repository marked private GitHub, need GitHub Personal Access Token (PAT) access . Put call ‘XXXX’ string.","code":"library(remotes) remotes::install_github(\"osparcomm/harsat\", auth_token = 'XXXX')"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/CONTRIBUTING.html","id":"issues","dir":"","previous_headings":"Contributing","what":"Issues","title":"Contributor’s Guide","text":"can report issues harsat using Github. Simply use Issues tab choose New issue. report issue, ’d like answer following questions. version harsat using? (’s DESCRIPTION file) version R using? operating system using? observing appears incorrect, expecting see? last point, information can give us, better. can copy paste R console logs helps tremendously, ’re 30 lines , ’s better attach file, rather pasting issue directly.","code":""},{"path":"http://osparcomm.github.io/HARSAT/CONTRIBUTING.html","id":"pull-requests","dir":"","previous_headings":"Contributing","what":"Pull requests","title":"Contributor’s Guide","text":"welcome pull requests. easiest way fork repository Github, make changes want fork, push Github, create pull request using web interface. point show main repository can collaborate integrate code. Please note particularly keen improve code quality.","code":""},{"path":"http://osparcomm.github.io/HARSAT/CONTRIBUTING.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Contributor’s Guide","text":"documentation held within Github repository. use following flow. roxygen2 used source-code documentation. particularly welcome pull requests improve documentation. several vignettes vignettes directory. actually run harsat code (ones matching *.Rmd.orig) therefore precompiled, can take 15-20 minutes run. turns *.Rmd.orig corresponding *.Rmd files. , normal documentation building vignettes installation deploy files, along basic *.Rmd vignettes run harsat code. web site built using pkgdown – happens automatically pull requests merged main. documents code – run roxygen2 – need , manually. merge pull requests, web documentation used update GitHub Pages site: https://osparcomm.github.io/HARSAT/","code":""},{"path":"http://osparcomm.github.io/HARSAT/CONTRIBUTING.html","id":"documentation-build-process","dir":"","previous_headings":"Documentation","what":"Documentation build process","title":"Contributor’s Guide","text":"documentation entirely built automatically. intentional, , example, running tools (e.g., roxygen2) can change key package files breaking way. Also, vignettes pre-rendered, take long time install users. update documentation, use following steps R. change namespacing, API changes can cause vignette builds break. , create issue. Step 1. Run roxygen2 Step 2. Precompile vignettes bash: Step 3. Build check code Back R:","code":"library(devtools) roxygen2::roxygenize() R --quiet --vanilla < vignettes/precompile.R library(devtools) devtools::check()"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"data-adjustments-water","dir":"Articles","previous_headings":"","what":"Data adjustments: water","title":"HELCOM","text":"’ll use lattice package plot data can see go. Tables made dynamic using progressive enhancement external JavaScript package DataTables.","code":"library(tidyverse) #> ── Attaching core tidyverse packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 2.0.0 ── #> ✔ dplyr     1.1.2     ✔ readr     2.1.4 #> ✔ forcats   1.0.0     ✔ stringr   1.5.0 #> ✔ ggplot2   3.4.2     ✔ tibble    3.2.1 #> ✔ lubridate 1.9.2     ✔ tidyr     1.3.0 #> ✔ purrr     1.0.1      #> ── Conflicts ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() #> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(lattice)"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"data-summary","dir":"Articles","previous_headings":"Data adjustments: water","what":"Data summary","title":"HELCOM","text":"summary submissions country, first determinand year.","code":"water_data$data %>%    with(table(country, determinand)) %>%    print(zero.print = \".\") #>            determinand #> country       CD   PB PFOS TBSN+ #>   Estonia     29   29   28    23 #>   Germany   1371 1349    5   156 #>   Lithuania  267  267   47    55 #>   Poland     862  854   36   375 #>   Russia      23   23    .     .  water_data$data %>%    with(table(country, year)) %>%    print(zero.print = \".\") #>            year #> country     1995 1998 1999 2000 2003 2004 2005 2006 2007 2008 2009 2010 2011 #>   Estonia      .    .    .    .    .    .    .    .    .    .    .    .    . #>   Germany      .   88   87  176   73  154  158  114  138  206  189  213   82 #>   Lithuania    .    .    .    .    .    .    .    .   46   46   48   38   49 #>   Poland       .    .    .    .    .    .    .    .    .    .    .    .  133 #>   Russia       4   42    .    .    .    .    .    .    .    .    .    .    . #>            year #> country     2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>   Estonia      .    .    .    .    .   17    4   36   20   32 #>   Germany     98  134   82  122  121  142  136  129  135  104 #>   Lithuania   52   42   42   66   16    .   81   46   64    . #>   Poland     181   72  144   72  479  540  143  159  108   96 #>   Russia       .    .    .    .    .    .    .    .    .    ."},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"matrix-issues","dir":"Articles","previous_headings":"Data adjustments: water","what":"Matrix issues","title":"HELCOM","text":"summary matrix filtration data. Data matrix SPM deleted.","code":"water_data$data <- mutate(   water_data$data,   filtered = if_else(grepl(\"NF\", method_pretreatment), \"No\", \"Yes\") )  water_data$data %>%    with(table(matrix, filtered, useNA = \"ifany\")) %>%    print(zero.print = \".\") #>       filtered #> matrix   No  Yes #>    SPM   36    . #>    WT  2074 3689  water_data$data <- filter(   water_data$data,    matrix == \"WT\" )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"duplicate-records","dir":"Articles","previous_headings":"Data adjustments: water","what":"Duplicate records","title":"HELCOM","text":"following samples duplicated records - first retained.","code":"wk <- water_data$data %>%     group_by(sample, determinand, filtered) %>%    filter(n() >= 2) %>%    ungroup()    wk %>%    select(country, year, station_name, sample, determinand, filtered, replicate, value) %>%    arrange(country, year, sample, determinand, replicate) %>%   as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\") wk_rep <- wk$replicate  wk_keep <- wk %>%    select(sample, determinand, filtered, replicate, station_name, value) %>%    arrange(replicate) %>%    distinct(sample, determinand, filtered, value, .keep_all = TRUE) %>%    pull(replicate)  wk_drop <- setdiff(wk_rep, wk_keep)  water_data$data <- filter(   water_data$data,    !replicate %in% wk_drop )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"filtration-issues","dir":"Articles","previous_headings":"Data adjustments: water","what":"Filtration issues","title":"HELCOM","text":"’s summary whether data filtered determinand. PFOS TBSN+ unfiltered, fine. However, issues metals data, since filtered (preferred) unfiltered samples. ’s detailed look metals data (excluded Russian data old). Estonia: samples filtered. Germany: real mixture explored . Lithuania: unfiltered data 2007 (first year data). Maybe filtered data submitted incorrectly. now treated unfiltered (drop assessment unfiltered data last six monitoring years) Poland: samples filtered.","code":"water_data$data %>%    with(table(determinand, filtered)) %>%    print(zero.print = \".\") #>            filtered #> determinand   No  Yes #>       CD     677 1831 #>       PB     659 1845 #>       PFOS   116    . #>       TBSN+  609    . wk <- filter(   water_data$data,    country != \"Russia\",   determinand %in% c(\"CD\", \"PB\") )     wk %>%    with(table(filtered, country)) %>%    print(zero.print = \".\") #>         country #> filtered Estonia Germany Lithuania Poland #>      No        .    1244        46      . #>      Yes      58    1414       488   1716  wk %>%    with(table(filtered, year, country)) %>%    print(zero.print = \".\") #> , , country = Estonia #>  #>         year #> filtered 1998 1999 2000 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 #>      No     .    .    .    .    .    .    .    .    .    .    .    .    .    . #>      Yes    .    .    .    .    .    .    .    .    .    .    .    .    .    . #>         year #> filtered 2014 2015 2016 2017 2018 2019 2020 2021 #>      No     .    .    .    .    .    .    .    . #>      Yes    .    .    .   12    2   18   10   16 #>  #> , , country = Germany #>  #>         year #> filtered 1998 1999 2000 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 #>      No    88   87  176   73  154  119   24   24   32   32   69   62   36   32 #>      Yes    .    .    .    .    .   13   90  114  174  121  144   20   62  102 #>         year #> filtered 2014 2015 2016 2017 2018 2019 2020 2021 #>      No    24   32   20   44   48   22   46    . #>      Yes   58   90   96   68   66   72   58   66 #>  #> , , country = Lithuania #>  #>         year #> filtered 1998 1999 2000 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 #>      No     .    .    .    .    .    .    .   46    .    .    .    .    .    . #>      Yes    .    .    .    .    .    .    .    .   46   48   34   40   40   42 #>         year #> filtered 2014 2015 2016 2017 2018 2019 2020 2021 #>      No     .    .    .    .    .    .    .    . #>      Yes   42   34    .    .   58   46   58    . #>  #> , , country = Poland #>  #>         year #> filtered 1998 1999 2000 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 #>      No     .    .    .    .    .    .    .    .    .    .    .    .    .    . #>      Yes    .    .    .    .    .    .    .    .    .    .    .  123  151   72 #>         year #> filtered 2014 2015 2016 2017 2018 2019 2020 2021 #>      No     .    .    .    .    .    .    .    . #>      Yes  144   72  336  348  143  147   96   84"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"german-metals-data","dir":"Articles","previous_headings":"Data adjustments: water > Filtration issues","what":"German metals data","title":"HELCOM","text":"stations metals data last six monitoring years (2016-2021); second column shows whether metal samples period filtered, unfiltered, mixture. three stations mixture. full records samples stations. look intentional. Filtered unfiltered samples analysed separate time series.","code":"wk <- wk %>%    filter(country == \"Germany\") %>%   group_by(station_name) %>%    filter(max(year) >= 2016) %>%   ungroup()   wk_fun <- function(x) {   if (all(x == \"Yes\")) return(\"filtered\")   if (all(x == \"No\")) return(\"unfiltered\")   \"mixture\" }  wk1 <- wk %>%    filter(year >= 2016) %>%    group_by(station_name) %>%    summarise(type = wk_fun(filtered), .groups = \"drop_last\")  as.data.frame(wk1) %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\") wk_id <- wk1 %>%    filter(type == \"mixture\") %>%    pull(station_name)  wk %>%    filter(station_name %in% wk_id) %>%    with(table(filtered, year, station_name)) %>%    print(zero.print = \".\") #> , , station_name = OMBMPM2 #>  #>         year #> filtered 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 #>      No     1    2    4    4    4    8    4    4    4    2    2    2    4    4 #>      Yes    1    2    2    2    4    .    .    .    .    .    .    2    .    . #>         year #> filtered 2019 2020 #>      No     2    4 #>      Yes    .    . #>  #> , , station_name = OMBMPN3 #>  #>         year #> filtered 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 #>      No     .    .    .    4    4    8    4    4    4    2    4    2    4    4 #>      Yes    .    .    .    2    4    .    .    .    .    .    .    2    .    . #>         year #> filtered 2019 2020 #>      No     2    2 #>      Yes    .    . #>  #> , , station_name = OMO22 #>  #>         year #> filtered 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 #>      No     .    .    4    4    4    4    4    4    4    2    2    2    4    4 #>      Yes    .    .    .    .    .   20    .    .    .    .    .    .   12    . #>         year #> filtered 2019 2020 #>      No     2    4 #>      Yes    .    8"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"zero-concentrations","dir":"Articles","previous_headings":"Data adjustments: water > Filtration issues","what":"Zero concentrations","title":"HELCOM","text":"metals concentrations Lithuania 2008 reported value = 0. measurements less LoQ (Nijole 22 August) value replaced LoQ. (uncertainties reported, need adjust .)","code":"water_data$data <- mutate(   water_data$data,    .id = value == 0 )  if (sum(water_data$data$.id) != 23) {   stop(\"something has changed - investigate\") }    water_data$data %>%    filter(.id) %>%    select(     country, year, determinand, value, censoring, limit_detection,      limit_quantification, uncertainty, unit_uncertainty   ) %>%    as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\") water_data$data <- mutate(   water_data$data,    value = if_else(.id, limit_quantification, value),   .id = NULL )"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"data-summary-1","dir":"Articles","previous_headings":"Sediment","what":"Data summary","title":"HELCOM","text":"summary submissions country, first determinand year. grain size fraction data omitted simplicity.","code":"wk <- filter(   sediment_data$data,    !grepl(\"GSMF\", determinand) )  wk %>%    with(table(country, determinand)) %>%    print(zero.print = \".\") #>            determinand #> country      AL ANT BD100 BD153 BD154 BDE28 BDE47 BDE99  CD CORG CTOT  CU #>   Denmark   498 374   111    56   114     .    98   104 479  467   30 485 #>   Estonia    23  28    30    30    30    30    30    30  28   23    .  28 #>   Finland     8  22     9     9     9     9     9     9  20    8    .   8 #>   Germany   307 129     4     4     3     5     4     4 362  411    . 327 #>   Latvia      .   .     .     .     .     .     .     .   .    .    .   1 #>   Lithuania 125  43    14    14    14    12    14    14 187    8    . 172 #>   Norway      6   6     .     .     .     .     .     .   6    6    .   6 #>   Poland    136  10     .     .     .     .     .     .  43    .    .  43 #>   Russia      .  13     .     .     .     .     .     .   9    .    .   9 #>   Sweden    237  60    56    42    42    28    56    56 245  225  126 245 #>            determinand #> country     DRYWT% FLU HBCD HBCDA HBCDB HBCDG  LI LOIGN  PB TBSN+ TBTIN #>   Denmark      481 448    .     .     .     . 469   515 482     .   402 #>   Estonia        2  28    .     .     .     .   .     .  28    28     . #>   Finland        8  22    .     4     4     4   8     .  20    21     . #>   Germany       15 127    .     .     .     . 233    70 367   102    34 #>   Latvia         .   .    .     .     .     .   .     .   1     .     . #>   Lithuania      8  43    8     8     8     8   .     . 187     7     . #>   Norway         .   6    .     .     .     .   6     .   6     .     . #>   Poland       327  27    .     .     .     .   .   278  43     8     . #>   Russia         .  13    .     .     .     .   .     .   9     .     . #>   Sweden       255  60   14    14    14    14 139   108 245    56     4  wk %>%    with(table(country, year)) %>%    print(zero.print = \".\") #>            year #> country     1985 1990 1991 1993 1995 1996 1997 1998 1999 2000 2001 2002 2003 #>   Denmark     10    .  135    .    .    .    .    .  217  452  152    .  711 #>   Estonia      .    .    .    .    .    .    .    .    .    .    .    .    . #>   Finland      .    .    .    .    .    .    .    .    .    .    .    .    . #>   Germany      .    .    .  461    .    .    .   94   75  138   48  166   42 #>   Latvia       .    .    .    .    .    2    .    .    .    .    .    .    . #>   Lithuania    .    .    .    .    .    .    .    .    .    .    .    .    . #>   Norway       .   48    .    .    .    .    .    .    .    .    .    .    . #>   Poland       .    .    .    .    .    .    .    6    6   12    .   78   39 #>   Russia       .    .    .    .   10    .   35    8    .    .    .    .    . #>   Sweden       .   28    .    .    .    .    .    .    .    .    4    .  196 #>            year #> country     2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 #>   Denmark     40    .    .  329 1221  328  121  351  360  351  451  209  175 #>   Estonia      .    .    .    .    .    .    .    .    .    .    .    .    . #>   Finland      .    .    .    .    .    .    .    .   28    .    .    4    . #>   Germany    138   84   40   56  184   70  175  191  107   98   81    .  105 #>   Latvia       .    .    .    .    .    .    .    .    .    .    .    .    . #>   Lithuania   21    .    .   45   33   51   44   65   70   60   92  116   44 #>   Norway       .    .    .    .    .    .    .    .    .    .    .    .    . #>   Poland       .    .    .   95    .    .    .    .  189   27    .   56   80 #>   Russia       .    .    .    .    .    .    .    .    .    .    .    .    . #>   Sweden       .    .    5    .  238    .    .    5    .    .  859    .    . #>            year #> country     2017 2018 2019 2020 2021 #>   Denmark      .    .    .    .    . #>   Estonia     60   13  128   83  112 #>   Finland     42    .   68   31   38 #>   Germany     45   90    .   20    . #>   Latvia       .    .    .    .    . #>   Lithuania   44   48   42  119    . #>   Norway       .    .    .    .    . #>   Poland       .  174    .   35  118 #>   Russia       .    .    .    .    . #>   Sweden       .    .    .  910   96"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"organotins","dir":"Articles","previous_headings":"Sediment","what":"Organotins","title":"HELCOM","text":"Denmark, Germany Sweden submitted TBTIN data (opposed TBSN+ data). TBTIN data ambiguous longer allowed. represent tin ion concentration trybutyltin cation concentration. (TBSN+ cation concentration). detailed breakdown year. Sweden: four TBTIN samples 1990 drop assessment anyway big gap next monitoring year 2003 - deleted avoid ambiguity Germany: 34 TBTIN samples 2000, 2002 2004 - ‘old’ data, deleted avoid ambiguity Denmark: data reported TBTIN. tin concentrations (Owen 22 August) converted cation concentrations multiplying 2.44. Use ctsm_TBT_convert helper function help .","code":"wk <- sediment_data$data %>%    filter(     determinand %in% c(\"TBSN+\", \"TBTIN\"),     country %in% c(\"Denmark\", \"Germany\", \"Sweden\")   )      wk %>%    with(table(determinand, year, country)) %>%   print(zero.print = \".\") #> , , country = Denmark #>  #>            year #> determinand 1990 1999 2000 2001 2002 2003 2004 2007 2008 2009 2010 2011 2012 #>       TBSN+    .    .    .    .    .    .    .    .    .    .    .    .    . #>       TBTIN    .   12   41   14    .   72    4    6   59   15    2   32   33 #>            year #> determinand 2013 2014 2015 2016 2018 2020 2021 #>       TBSN+    .    .    .    .    .    .    . #>       TBTIN   32   43   21   16    .    .    . #>  #> , , country = Germany #>  #>            year #> determinand 1990 1999 2000 2001 2002 2003 2004 2007 2008 2009 2010 2011 2012 #>       TBSN+    .    .    .    .    .    .    .    .   16    7   18   12    9 #>       TBTIN    .    .   10    .   14    .   10    .    .    .    .    .    . #>            year #> determinand 2013 2014 2015 2016 2018 2020 2021 #>       TBSN+    8    2    .   10   15    5    . #>       TBTIN    .    .    .    .    .    .    . #>  #> , , country = Sweden #>  #>            year #> determinand 1990 1999 2000 2001 2002 2003 2004 2007 2008 2009 2010 2011 2012 #>       TBSN+    .    .    .    .    .   14    .    .   14    .    .    .    . #>       TBTIN    4    .    .    .    .    .    .    .    .    .    .    .    . #>            year #> determinand 2013 2014 2015 2016 2018 2020 2021 #>       TBSN+    .   14    .    .    .    6    8 #>       TBTIN    .    .    .    .    .    .    . sediment_data$data <- filter(   sediment_data$data,    !(determinand %in% \"TBTIN\" & country %in% c(\"Germany\", \"Sweden\")) )  sediment_data$data <- ctsm_TBT_convert(   sediment_data$data,    country %in% \"Denmark\",    action = c(\"relabel\", \"convert\") )"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"germany-station-bmp-k4","dir":"Articles","previous_headings":"Stations","what":"Germany station BMP K4","title":"HELCOM","text":"Data submitted stations BMP K4 OMBMPK4 regarded BMP K4 (Berit, 6 October 2022). submitted stations resulting station names extraction procedure (based coordinates) given year. possibility duplication 2011 2017 data submitted BMP K4 OMBPK4. determinands submitted year. duplication 2017, eight values submitted twice 2011. Delete 2011 values OMBPK4 relabel OMBPK4 data BMP K4","code":"wk_data <- filter(   sediment_data$data,   submitted.station %in% c(\"BMP K4\", \"OMBMPK4\") )   wk_data %>%    with(table(station_name, year, submitted.station)) %>%    print(zero.print = \".\") #> , , submitted.station = BMP K4 #>  #>             year #> station_name 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2016 #>      BMP K4     .    .    .    .    .    .    .    .    9    3    9    .    6 #>      OMBMPK4    .    .    .    .    .    .    .    .    .    .    .    .    . #>             year #> station_name 2017 2018 2020 #>      BMP K4     7    .    . #>      OMBMPK4    .    .    . #>  #> , , submitted.station = OMBMPK4 #>  #>             year #> station_name 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2016 #>      BMP K4     .    .    .    7   10    8    8   14    8    .    .    9    . #>      OMBMPK4    8   10   18    2    .    .    .    .    .    .    .    .    . #>             year #> station_name 2017 2018 2020 #>      BMP K4     .    .    . #>      OMBMPK4    3    4    4 wk_data %>%    filter(year %in% c(2011, 2017)) %>%    with(table(submitted.station, determinand, year)) %>%    print(zero.print = \".\") #> , , year = 2011 #>  #>                  determinand #> submitted.station AL ANT CD CORG CU FLU GSMF20 GSMF2000 LI PB #>           BMP K4   1   1  1    2  1   1      .        .  1  1 #>           OMBMPK4  1   1  1    1  1   1      .        .  1  1 #>  #> , , year = 2017 #>  #>                  determinand #> submitted.station AL ANT CD CORG CU FLU GSMF20 GSMF2000 LI PB #>           BMP K4   1   .  1    .  1   .      1        1  1  1 #>           OMBMPK4  .   1  .    1  .   1      .        .  .  .  wk_data %>%    filter(year %in% 2011) %>%   select(submitted.station, determinand, matrix, value) %>%    arrange(determinand, submitted.station) #>    submitted.station determinand matrix     value #> 1             BMP K4          AL  SED20    39.300 #> 2            OMBMPK4          AL  SED20    39.300 #> 3             BMP K4         ANT SEDTOT     1.057 #> 4            OMBMPK4         ANT SEDTOT     1.057 #> 5             BMP K4          CD  SED20   120.000 #> 6            OMBMPK4          CD  SED20   120.000 #> 7             BMP K4        CORG  SED20    58.400 #> 8             BMP K4        CORG SEDTOT    60.900 #> 9            OMBMPK4        CORG  SED20    58.400 #> 10            BMP K4          CU  SED20 41000.000 #> 11           OMBMPK4          CU  SED20 41000.000 #> 12            BMP K4         FLU SEDTOT     4.917 #> 13           OMBMPK4         FLU SEDTOT     4.917 #> 14            BMP K4          LI  SED20    41.000 #> 15           OMBMPK4          LI  SED20    41.000 #> 16            BMP K4          PB  SED20 79000.000 #> 17           OMBMPK4          PB  SED20 79000.000  wk_code <- get_station_code(\"BMP K4\", \"Germany\", sediment_data$stations) #> Warning: There was 1 warning in `mutate()`. #> ℹ In argument: `across(.fns = as.character)`. #> Caused by warning: #> ! Using `across()` without supplying `.cols` was deprecated in dplyr 1.1.0. #> ℹ Please supply `.cols` instead.  sediment_data$data <- sediment_data$data %>%    filter(!(year == 2011 & submitted.station == \"OMBMPK4\")) %>%    mutate(     .change = submitted.station == \"OMBMPK4\",     station_name = if_else(.change, \"BMP K4\", station_name),     station_code = if_else(.change, wk_code, station_code),     .change = NULL   )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"matrix-issues-1","dir":"Articles","previous_headings":"Stations","what":"Matrix issues","title":"HELCOM","text":"summary matrix submissions country. focus ‘relevant’ data, stations monitored last six monitoring years (2016-2021) considered. Grain size fraction data also omitted. Germany Poland submitted multiple matrices worth investigating going . Note SED62 treated SED63 code; similarly SED2000 treated SEDTOT.","code":"wk <- sediment_data$data %>%    filter(     !is.na(station_name),      !grepl(\"GSMF\", determinand)   ) %>%    group_by(station_name) %>%    filter(any(year >= 2016)) %>%    ungroup()    wk %>%    with(table(matrix, country)) %>%    print(zero.print = \".\") #>          country #> matrix    Denmark Estonia Finland Germany Lithuania Poland Sweden #>   SED20         .       .       .     849         .      .      . #>   SED2000     247       .       .     229         .     12      . #>   SED62         .       .       .       .         .      1      . #>   SED63         .       .       .      82         .    838   2294 #>   SEDTOT        .     396     183     213       787      .      ."},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"poland","dir":"Articles","previous_headings":"Stations","what":"Poland","title":"HELCOM","text":"SED2000 data 2000 earlier, deleted avoid confusion SED63 (SED62) data.","code":"wk %>%    filter(country == \"Poland\") %>%    with(table(matrix, year)) %>%    print(zero.print = \".\") #>          year #> matrix    1998 1999 2000 2002 2003 2007 2012 2013 2015 2016 2018 2020 2021 #>   SED2000    6    3    3    .    .    .    .    .    .    .    .    .    . #>   SED62      .    .    .    1    .    .    .    .    .    .    .    .    . #>   SED63      .    .    .   51   13   95  189   27   56   80  174   35  118  sediment_data$data <- filter(   sediment_data$data,     !(country == \"Poland\" & matrix == \"SED2000\") )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"germany","dir":"Articles","previous_headings":"Stations","what":"Germany","title":"HELCOM","text":"summary German data matrix. organics (apart three TBSN+ samples) measured SED2000 (SEDTOT). metals measured SED20, SED63 SED2000. three TBSN+ samples SED63 TBSN+ data station OMBMPK8 last sampled 2012, don’t need worry . summary TBSN+ submissions stations SDE63 used. summary matrix sumbissions metals station matrix. data SED20. turns SED2000 measurements ‘replicates’ sense samples already SED20 measurements. Since SED20 appears target matrix, makes sense delete SED2000 measurements. left. appears change strategy stations, switching SED63 2012. matrix records stations metals sampled SED20 SED63. ensure time series consistent matrix, SED20 records stations 2012 deleted.","code":"wk <- filter(wk, country == \"Germany\")  wk %>%    with(table(determinand, matrix)) %>%    print(zero.print = \".\") #>            matrix #> determinand SED20 SED2000 SED63 SEDTOT #>      AL       148       3     .      . #>      ANT        .      47     .     58 #>      BD100      .       3     .      . #>      BD153      .       3     .      . #>      BD154      .       3     .      . #>      BDE28      .       4     .      . #>      BDE47      .       3     .      . #>      BDE99      .       3     .      . #>      CD       147       3    38      . #>      CORG     134      33     3     61 #>      CU       147       3     .      . #>      DRYWT%     .       .     .     15 #>      FLU        .      44     .     59 #>      LI        97       3     .      . #>      LOIGN     30      30     .     10 #>      PB       146       3    38      . #>      TBSN+      .      41     3     10 wk %>%    filter(determinand %in% \"TBSN+\") %>%    group_by(station_name) %>%    filter(any(matrix %in% \"SED63\")) %>%    ungroup() %>%    with(table(matrix, year, station_name)) %>%    print(zero.print = \".\") #> , , station_name = OMBMPK8 #>  #>        year #> matrix  2009 2011 2012 #>   SED63    1    1    1 sediment_data$data <- sediment_data$data %>%   mutate(     .id = country %in% \"Germany\" & determinand %in% c(\"CD\", \"PB\", \"CU\"),      .recent = station_name %in% wk$station_name,     .target_matrix = matrix %in% \"SED20\"   ) %>%    unite(\".sample\", sample, determinand, remove = FALSE)  sediment_data$data %>%    filter(.id & .recent) %>%   with(table(station_name, matrix)) %>%    print(zero.print = \".\") #>             matrix #> station_name SED20 SED2000 SED63 #>     BMP K4      42       .     . #>     Oderbank    12       .     . #>     OM225027    15       .     8 #>     OM225054     .       .     2 #>     OM225059    15       .     8 #>     OM701       15       .     8 #>     OM708       15       .     8 #>     OM714       15       .     8 #>     OMBMPK7     55       3     . #>     OMBMPK8     58       3     . #>     OMBMPM2     63       3     . #>     OMBMPN1     30       .     . #>     OMBMPN3     30       .     . #>     OMF1        15       .     8 #>     OMMB3       15       .     8 #>     OMMB6       15       .     6 #>     OMS2        15       .     6 #>     OMS3        15       .     6 wk_sample <- sediment_data$data %>%    filter(.id & .target_matrix) %>%    pull(.sample) %>%    unique()  sediment_data$data <- filter(   sediment_data$data,   !(.sample %in% wk_sample & matrix %in% \"SED2000\") )  sediment_data$data %>%    filter(.id & .recent) %>%   with(table(station_name, matrix)) %>%    print(zero.print = \".\") #>             matrix #> station_name SED20 SED63 #>     BMP K4      42     . #>     Oderbank    12     . #>     OM225027    15     8 #>     OM225054     .     2 #>     OM225059    15     8 #>     OM701       15     8 #>     OM708       15     8 #>     OM714       15     8 #>     OMBMPK7     55     . #>     OMBMPK8     58     . #>     OMBMPM2     63     . #>     OMBMPN1     30     . #>     OMBMPN3     30     . #>     OMF1        15     8 #>     OMMB3       15     8 #>     OMMB6       15     6 #>     OMS2        15     6 #>     OMS3        15     6 wk_id <- sediment_data$data %>%    filter(.id & .recent) %>%    group_by(station_name) %>%    filter(all(c(\"SED63\", \"SED20\") %in% matrix)) %>%    ungroup() %>%    pull(station_name) %>%    unique()  sediment_data$data %>%    filter(.id & .recent & station_name %in% wk_id) %>%   with(table(matrix, year)) %>%    print(zero.print = \".\") #>        year #> matrix  2000 2002 2004 2008 2010 2012 2014 2016 2018 #>   SED20   30   30   30   30   30    .    .    .    . #>   SED63    .    .    .    .    .   20   16   18   20 sediment_data$data <- sediment_data$data %>%    filter(!(.id & station_name %in% wk_id & matrix %in% \"SED20\")) %>%   mutate(     .id = NULL,      .recent = NULL,     .sample = NULL,     .target_matrix = NULL   )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"sbde6","dir":"Articles","previous_headings":"Stations","what":"SBDE6","title":"HELCOM","text":"info, PBDE measurements country (filtered stations monitored last six years). constructing sum six PBDEs, lose following data due incomplete submissions: 2012 data Lithuania (BDE28) 2003 2008 data Sweden. (Note HOLAS 2 required six PBDEs present, although turned sample corresponding organic carbon measurement, data dropped anyway.)","code":"wk <- sediment_data$data %>%   filter(grepl(\"BD\", determinand)) %>%    group_by(station_name) %>%    filter(any(year >= 2016)) %>%    ungroup()  wk %>%    with(table(determinand, year, country)) %>%    print(zero.print = \".\") #> , , country = Estonia #>  #>            year #> determinand 2003 2008 2012 2014 2017 2018 2019 2020 2021 #>       BD100    .    .    .    .    5    1    9    7    8 #>       BD153    .    .    .    .    5    1    9    7    8 #>       BD154    .    .    .    .    5    1    9    7    8 #>       BDE28    .    .    .    .    5    1    9    7    8 #>       BDE47    .    .    .    .    5    1    9    7    8 #>       BDE99    .    .    .    .    5    1    9    7    8 #>  #> , , country = Finland #>  #>            year #> determinand 2003 2008 2012 2014 2017 2018 2019 2020 2021 #>       BD100    .    .    .    .    .    .    4    2    3 #>       BD153    .    .    .    .    .    .    4    2    3 #>       BD154    .    .    .    .    .    .    4    2    3 #>       BDE28    .    .    .    .    .    .    4    2    3 #>       BDE47    .    .    .    .    .    .    4    2    3 #>       BDE99    .    .    .    .    .    .    4    2    3 #>  #> , , country = Lithuania #>  #>            year #> determinand 2003 2008 2012 2014 2017 2018 2019 2020 2021 #>       BD100    .    .    2    3    .    .    .    8    . #>       BD153    .    .    2    3    .    .    .    8    . #>       BD154    .    .    2    3    .    .    .    8    . #>       BDE28    .    .    .    3    .    .    .    8    . #>       BDE47    .    .    2    3    .    .    .    8    . #>       BDE99    .    .    2    3    .    .    .    8    . #>  #> , , country = Sweden #>  #>            year #> determinand 2003 2008 2012 2014 2017 2018 2019 2020 2021 #>       BD100   14   14    .   14    .    .    .    6    8 #>       BD153    .   14    .   14    .    .    .    6    8 #>       BD154    .   14    .   14    .    .    .    6    8 #>       BDE28    .    .    .   14    .    .    .    6    8 #>       BDE47   14   14    .   14    .    .    .    6    8 #>       BDE99   14   14    .   14    .    .    .    6    8"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"basis","dir":"Articles","previous_headings":"Stations","what":"Basis","title":"HELCOM","text":"basis submissions (apart grain size fractions drywt%). Wet weight submissions unusual. Lithuanian submissions confirmed correct (Nijole, 19 August 2022). Finnish submissions dry weight (Emmi, 16 August 2022) corrected .","code":"wk <- sediment_data$data %>%    filter(     !grepl(\"GSMF\", determinand),      determinand != \"DRYWT%\",      !is.na(station_name)   ) %>%    group_by(station_name) %>%    filter(any(year >= 2016)) %>%   ungroup()  wk %>%    with(table(country, basis)) %>%    print(zero.print = \".\") #>            basis #> country        D    W #>   Denmark    227    . #>   Estonia    394    . #>   Finland    169    6 #>   Germany   1199    . #>   Lithuania  748   33 #>   Poland     532    . #>   Sweden    2043    . wk %>%    filter(basis == \"W\") %>%    with(table(determinand, year, country)) %>%    print(zero.print = \".\") #> , , country = Finland #>  #>            year #> determinand 2015 2020 #>       CD       .    3 #>       CORG     .    . #>       HBCD     .    . #>       HBCDA    .    . #>       HBCDB    .    . #>       HBCDG    .    . #>       PB       .    3 #>       TBSN+    .    . #>  #> , , country = Lithuania #>  #>            year #> determinand 2015 2020 #>       CD       .    . #>       CORG     6    . #>       HBCD     6    . #>       HBCDA    6    . #>       HBCDB    6    . #>       HBCDG    6    . #>       PB       .    . #>       TBSN+    3    .  sediment_data$data <- mutate(   sediment_data$data,    .id = basis == \"W\" & country == \"Finland\" & year == 2020 )  if (sum(sediment_data$data$.id) != 6) {   stop(\"something has changed - investigate\") }  sediment_data$data <- mutate(   sediment_data$data,    basis = if_else(.id, \"D\", basis),   .id = NULL )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"poland---multiple-depths","dir":"Articles","previous_headings":"Stations","what":"Poland - multiple depths","title":"HELCOM","text":"Poland analysed auxiliary data (AL, DRYWT% LOIGN) multiple depths. Just retain surface measurements compatibility contaminant measurements.","code":"sediment_data$data %>%    filter(     country == \"Poland\"   ) %>%    with(table(determinand, depth)) %>%    print(zero.print = \".\") #>            depth #> determinand  0 0.01 0.02 0.03 0.04 0.06 0.08 0.15 0.22 0.29 #>      AL     17    .   17    .   17   17   17   17   17   17 #>      ANT    10    .    .    .    .    .    .    .    .    . #>      CD     35    .    .    .    .    .    .    .    .    . #>      CU     35    .    .    .    .    .    .    .    .    . #>      DRYWT% 48   10   48   10   48   38   38   29   29   29 #>      FLU    27    .    .    .    .    .    .    .    .    . #>      LOIGN  40    5   40    5   40   35   35   26   26   26 #>      PB     35    .    .    .    .    .    .    .    .    . #>      TBSN+   8    .    .    .    .    .    .    .    .    .  sediment_data$data <- filter(   sediment_data$data,    !(country == \"Poland\" & depth >= 0.01) )"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"aluminium","dir":"Articles","previous_headings":"Normalisers","what":"Aluminium","title":"HELCOM","text":"plot aluminium concentrations (%) ‘relevant’ time series year country. values seem broadly compatible normalising 5% aluminium. However, values Lithuania Estonia suspiciously small worth looking detail. plot chunk helcom-data-adjust-sed_AL1 Lithuanian aluminium measurements . confirmed correct (Nijole, 19 August 2022) mostly lower values find pure sand (even weak digestion method). plot chunk helcom-data-adjust-sed_AL2 Estonian aluminium measurements. low relative countries, pronounced Lithuania. corresponding organic carbon measurements also low, probably monitoring sandy sediments without sieving. plot chunk helcom-data-adjust-sed_AL3","code":"wk <- sediment_data$data %>%    filter(!is.na(station_name)) %>%    group_by(station_name) %>%    filter(any(year >= 2016)) %>%    ungroup()   wk <- wk %>%    filter(determinand %in% c(\"AL\", \"CORG\", \"LOIGN\")) %>%    mutate(value = convert_units(value, unit, \"%\"))  lattice::xyplot(   value ~ year | country,    data = subset(wk, determinand == \"AL\"),    col = \"black\",    scales = list(alternating = FALSE) ) wk1 <- filter(wk, determinand == \"AL\" & country == \"Lithuania\")  lattice::xyplot(   value ~ year,    data = wk1,    col = \"black\",  ) wk1 <- filter(wk, determinand == \"AL\" & country == \"Estonia\")  lattice::xyplot(   value ~ year,    data = wk1,    col = \"black\",  )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"corg-loign","dir":"Articles","previous_headings":"Normalisers","what":"CORG / LOIGN","title":"HELCOM","text":"plot CORG (blue) LOIGN (purple) concentrations (%) ‘relevant’ time series year country. LOIGN used normalising whenever CORG available. Assuming CORG = 0.35 \\(\\times\\) LOIGN (Owen, 17 August 2022) normalising 5% CORG equivalent normalising 14.3% LOIGN. plot chunk helcom-data-adjust-sed_corg plot CORG values , without distortion caused LOIGN values. values Estonia nearly less-thans (<0.1%) supports interpretation sediments nearly pure sand. plot chunk helcom-data-adjust-sed_corg2","code":"lattice::xyplot(   value ~ year | country,    data = subset(wk, determinand %in% c(\"CORG\", \"LOIGN\")),    groups = determinand,   scales = list(alternating = FALSE) ) wk <- sediment_data$data %>%    filter(!is.na(station_name)) %>%    group_by(station_name) %>%    filter(any(year >= 2016)) %>%    ungroup()   wk <- wk %>%    filter(determinand %in% \"CORG\") %>%    mutate(value = convert_units(value, unit, \"%\"))   lattice::xyplot(   value ~ year | country,    data = wk,    col = \"black\",   scales = list(alternating = FALSE) )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"sweden---missing-corg","dir":"Articles","previous_headings":"Normalisers","what":"Sweden - missing CORG","title":"HELCOM","text":"Sweden missing CORG sediment samples 2020 2021 organic contaminants measured. Apparently, samples damaged / lost CORG measured. 2021, values provided Johan (3 October 2022) based new samples taken locations. 2021 samples extraction: Next, let’s find whether ’re using “old” “new” data format, store variable can use . values CORG provided Johan, merged main data set. 2020, samples supporting CORG others don’t. number samples station, corresponding number CORG measurements. (stations replicate measurements sample.) ‘missing’ CORG values taken median CORG measurement station.","code":"wk_data <- sediment_data$data %>%    filter(     country == \"Sweden\",      year == 2021   )   with(wk_data, table(sample, determinand)) #>          determinand #> sample    ANT BD100 BD153 BD154 BDE28 BDE47 BDE99 FLU HBCDA HBCDB HBCDG TBSN+ #>   3624467   1     1     1     1     1     1     1   1     1     1     1     1 #>   3624468   1     1     1     1     1     1     1   1     1     1     1     1 #>   3624469   1     1     1     1     1     1     1   1     1     1     1     1 #>   3624470   1     1     1     1     1     1     1   1     1     1     1     1 #>   3624471   1     1     1     1     1     1     1   1     1     1     1     1 #>   3624472   1     1     1     1     1     1     1   1     1     1     1     1 #>   3624473   1     1     1     1     1     1     1   1     1     1     1     1 #>   3624476   1     1     1     1     1     1     1   1     1     1     1     1 # By default, set a format flag to \"old\" wk_data_format <- \"old\"  # Overwrite this value if a format was specified in the call if (!is.null(sediment_data$call$data_format)) {   wk_data_format <- sediment_data$call$data_format } wk_new <-    read.csv(     file.path(working.directory, \"data\", \"example_HELCOM\", \"SE_missing_CORG_sediment.csv\"),     na.string = \"\"   ) %>%   select(tblSampleID, Value, MUNIT)  wk_new #>   tblSampleID Value MUNIT #> 1     3624469 12.27     % #> 2     3624467  5.79     % #> 3     3624468  6.08     % #> 4     3624476  2.42     % #> 5     3624471 12.37     % #> 6     3624470 11.41     % #> 7     3624473 14.02     % #> 8     3624472 11.48     %  wk_new <- wk_new %>%   select(- MUNIT) %>%   mutate(tblSampleID = as.character(tblSampleID))  wk_data <- filter(wk_data, determinand == \"ANT\")  wk_data <- left_join(wk_data, wk_new, by = c(\"sample\" = \"tblSampleID\"))  wk_data <- mutate(   wk_data,   indicator = \"Supplemental\",   pargroup = \"O-MAJ\",   determinand = \"CORG\",   value = Value,   unit = \"%\",   censoring = NA_character_,   method_analysis = NA_character_,   limit_detection = NA_real_,   limit_quantification = NA_real_,    uncertainty = NA_real_,    unit_uncertainty = NA_character_,    alabo = \"NSLS\",   qalink = 0,   replicate = 1:nrow(wk_data) + max(sediment_data$data$replicate),   Value = NULL )  if (wk_data_format == \"new\") wk_data$indicator <- NULL  sediment_data$data <- bind_rows(sediment_data$data, wk_data) wk_data <- filter(   sediment_data$data,   country == \"Sweden\",   year == 2020 )  wk_data %>%    group_by(station_name) %>%   summarise(n_sample = length(unique(sample)), n_CORG = sum(determinand %in% \"CORG\"), .groups = \"drop\") %>%   as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\") wk_CORG <- filter(wk_data, determinand %in% \"CORG\")  # identify samples in wk_data with no CORG  wk_data <- wk_data %>%    filter(!(sample %in% wk_CORG$sample)) %>%   distinct(sample, .keep_all = TRUE)  wk_CORG <- by(wk_CORG, wk_CORG$station_name, function(x) {   x <- arrange(x, value)   id <- floor((nrow(x) + 1) / 2)   x[id, ] })  wk_CORG <- do.call(rbind, wk_CORG)   wk_id <- c(   \"pargroup\", \"determinand\", \"basis\", \"unit\",   \"value\", \"censoring\", \"limit_detection\", \"limit_quantification\", \"uncertainty\",   \"unit_uncertainty\", \"alabo\", \"method_analysis\", \"smtyp\", \"qalink\" )  if (wk_data_format == \"old\") {   wk_id <- append(wk_id, c(\"indicator\", \"ges_matrix\"), after = 0) }  wk_data[, wk_id] <- wk_CORG[wk_data$station_name, wk_id]  wk_data$replicate <- 1:nrow(wk_data) + max(sediment_data$data$replicate)  sediment_data$data <- bind_rows(sediment_data$data, wk_data)  rm(wk_data, wk_CORG)"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"multiple-method_extraction","dir":"Articles","previous_headings":"Normalisers","what":"Multiple method_extraction","title":"HELCOM","text":"instances multiple method_extraction sediment QA file. unusual. single methods, new method_extraction codes set . Unfortunately, R code can’t currently deal , modify sensibly. methods determinands used (relevant HELCOM assessment) Fortunately, organics, method_extraction isn’t used. replace e.g. ACH~PLE ACE etc. HNO-CM~LMF--L problematic, metals combination strong total digestion method, doesn’t make sense. Fortunately, doesn’t matter time series metals data analysed method finished 2014 (see ). can replace code HNO-CM without impact assessment.","code":"sediment_data$QA %>%    filter(     data_type == \"CS\",     determinand %in% c(       ctsm_get_determinands(\"sediment\"),       \"BDE28\", \"BDE47\", \"BDE99\", \"BD100\", \"BD153\", \"BD154\", \"HBCDA\", \"HBCDB\", \"HBCDG\"     ),     grepl(\"~\", method_extraction, fixed = TRUE)   ) %>%   distinct(method_extraction, determinand, alabo) %>%   arrange(method_extraction, alabo) %>%   select(method_extraction, alabo, determinand) %>%   as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\") sediment_data$QA <- mutate(   sediment_data$QA,   method_extraction = recode(     method_extraction,     \"ACH~PLE\" = \"ACH\",     \"ACE~PLE~TOL\" = \"ACE\",     \"DCM~METH\" = \"DCM\",     \"HAC~METH\" = \"HAC\",     \"HX~SPE-DCM~PLE\" = \"HX\",     \"SOX~TOL\" = \"SOX\"   ) )  wk_id <- sediment_data$QA %>%   filter(     data_type == \"CS\",      determinand %in% c(\"CD\", \"HG\", \"CU\"),     method_extraction == \"HNO-CM~LMF-A-L\"   ) %>%   distinct(alabo, year) %>%   unite(.id) %>%   pull(.id)  wk_id <- sediment_data$data %>%   unite(\".id\", alabo, year) %>%   filter(.id %in% wk_id) %>%   pull(station_code) %>%   unique()  sediment_data$data %>%   filter(     determinand %in% c(\"CD\", \"PB\", \"CU\"),     station_code == 11167   ) %>%   select(country, station_code, station_name, alabo, determinand, year) %>%   arrange(year)  sediment_data$QA <- mutate(   sediment_data$QA,   method_extraction = recode(method_extraction, \"HNO-CM~LMF-A-L\" = \"HNO-CM\") )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"missing-uncertainties-loign","dir":"Articles","previous_headings":"Normalisers","what":"Missing uncertainties LOIGN","title":"HELCOM","text":"Missing uncertainties determinands LOIGN imputed using fixed relative standard deviations derived OSPAR 2022 assessment. Fixed relative standard deviations LOIGN need estimated HELCOM data (LOIGN used OSPAR 2022 assessment). plot relative uncertainties LOIGN reported, country. (large Danish uncertainties omitted - probably due unit errors.) plot chunk helcom-data-adjust-sed_uncrt1 relative standard deviations estimated using procedures used OSPAR, gives value 0.1 (10%). constant standard deviation set 0 (hardly less-measurements base ).","code":"wk <- sediment_data$data %>%    filter(determinand %in% \"LOIGN\") %>%   mutate(     value = convert_units(value, unit, \"%\"),     uncertainty = case_when(       unit_uncertainty == \"U2\" ~ 100 * (uncertainty / 2) / value,       unit_uncertainty == \"SD\" ~ 100 * uncertainty / value,       TRUE                      ~ uncertainty     ),     uncertainty = if_else(uncertainty >= 100, NA_real_, uncertainty)   ) %>%   drop_na(uncertainty)  xyplot(   uncertainty ~ value | country,   data = wk,   col = \"black\",   scales = list(alternating = FALSE),   ylab = \"relative uncertainty (%)\",   xlab = \"concentration (%)\" ) out_relative <- wk %>%   filter(     is.na(.data$censoring),     !is.na(alabo)   ) %>%    group_by(.data$determinand, .data$alabo, .data$country) %>%   summarise(sd_variable = median(.data$uncertainty) / 100, .groups = \"drop\")  # now the median value across alabos out_relative <- summarise(out_relative, sd_variable = median(sd_variable))"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"data-summary-2","dir":"Articles","previous_headings":"Biota","what":"Data summary","title":"HELCOM","text":"summary submissions country, first determinand year. less useful supporting data omitted simplicity (four UK records 1999).","code":"wk <- filter(   biota_data$data,   !grepl(\"TIN\", determinand),   determinand != \"IMPF%\",   country != \"United Kingdom\", )  wk %>%   with(table(country, determinand)) %>%   print(zero.print = \".\") #>            determinand #> country     %FEMALEPOP   BAP BD100 BD153 BD154 BDE28 BDE47 BDE99 BR-PFOS CB101 #>   Denmark            .  1012   124   123   124    88   107   119       .   519 #>   Estonia            .     .    27    27    27    27    27    27       .   210 #>   Finland            .     .   134   134   134   134   134   134       .   749 #>   Germany            .   156   353   314   367   355   358   367       .   569 #>   Latvia             .     .     6     6     6     6     6     6       .     9 #>   Lithuania          .     4    12    12    12    12    12    12       .     . #>   Poland             .    18   620   620   620   620   620   620       .  1152 #>   Sweden           298    31  1103  1078   467   470  2011  1997     282  2783 #>            determinand #> country     CB105 CB110 CB114 CB118 CB122 CB123 CB126 CB128 CB138 CB138+163 #>   Denmark     522   294    38   513     .    38    88   425   520         . #>   Estonia      28     .    28   211     .    28    28     .   211         . #>   Finland     155   119   107   749    48   107   107    71   748         . #>   Germany     443     .    14   524     .    14    14    99   569         . #>   Latvia        6     .     6     9     .     6     6     .     9         . #>   Lithuania    12     .    12    12     .    12    12     .     .         . #>   Poland        .     .     .  1152     .     .     .     .  1152         . #>   Sweden      505     .   425  3328     .   425   425     .  2283       503 #>            determinand #> country     CB141 CB149 CB151 CB153 CB156 CB157 CB167 CB169 CB170  CB18 CB180 #>   Denmark       .   377   246   521   523   108    38    89   446     .   520 #>   Estonia       .     .     .   211    28    28    28    28     .     .   208 #>   Finland      71    48     .   749   155   107   107   107   119    71   747 #>   Germany       .    98     .   568   445    14    14    14    24     .   569 #>   Latvia        .     .     .     9     6     6     6     6     .     .     9 #>   Lithuania     .     .     .     .    12    12    12    12     .     .     . #>   Poland        .     .     .  1152     .     .     .     .     .     .  1152 #>   Sweden        .     .     .  2785   505   505   505   505     .     .  2785 #>            determinand #> country     CB183 CB187 CB189 CB194 CB206 CB209  CB28  CB31  CB33  CB44  CB47 #>   Denmark       .   174    38     .     .     6   517   504     .   246     . #>   Estonia       .     .    28    10     .     .   209     .     .     .     . #>   Finland      71   119   107    71    71    71   708    48    71     .    71 #>   Germany       .     .    14     .     .     .   559     .     .     .     . #>   Latvia        .     .     6     .     .     .     8     .     .     .     . #>   Lithuania     .     .    12     .     .     .     .     .     .     .     . #>   Poland        .     .     .     .     .     .  1152     .     .     .     . #>   Sweden        .     .   425     .     .     .  2663     .     .     .     . #>            determinand #> country      CB49  CB51  CB52  CB60  CB66  CB74  CB77  CB81  CB99    CD CDD1N #>   Denmark     246     .   519     .     .     .    88    37   247  1913   105 #>   Estonia       .     .   211     .     .     .    28    28     .    98    26 #>   Finland      71    48   730    48   119    71   107   107    71   780   109 #>   Germany       .     .   559     .     .     .    14    14     .   743    14 #>   Latvia        .     .     9     .     .     .     6     6     .   262     . #>   Lithuania     .     .     .     .     .     .    12    12     .    96    12 #>   Poland        .     .  1152     .     .     .     .     .     .  1419     . #>   Sweden        .     .  2674     .     .     .   505   425     .  2835   585 #>            determinand #> country     CDD4X CDD6P CDD6X CDD9X  CDDO CDDSN CDDSP CDDST CDDSX CDF2N CDF2T #>   Denmark     106   105   106   105    80     .     .     .     .   105   105 #>   Estonia      26    26    26    26    26     .     .     .     .    26    26 #>   Finland     109   109   109   109   109     .     .     .     .   109   109 #>   Germany      14    14    14    14    14     .     .     .     .    14    14 #>   Latvia        .     .     .     .     6     6     6     6     6     .     6 #>   Lithuania    12    12    12    10     7     .     .     .     .    12    12 #>   Poland        .     .     .     .     .     .     .     .     .     .     . #>   Sweden      585   585   585   585   585     .     .     .     .   665   585 #>            determinand #> country     CDF4X CDF6P CDF6X CDF9P CDF9X CDFDN  CDFO CDFP2 CDFSN CDFSP CDFST #>   Denmark     105   104   106   105   105     .   102   105     .     .     . #>   Estonia      26    26    26    26    26     .     .    26     .     .     . #>   Finland     109   109   109   109   109     .     .   109     .     .     . #>   Germany      14    14    14    14    14     3     .    11     .     .     . #>   Latvia        .     .     .     .     .     .     .     .     6     6     6 #>   Lithuania    12    12    12    12    12     .     .    12     .     .     . #>   Poland        .     .     .     .     .     .     .     .     .     .     . #>   Sweden      585   585   585   585   585   320   583   425     .     .     . #>            determinand #> country     CDFSX CDFX1 DRYWT% EXLIP% FATWT%   FLU  HBCD HBCDA HBCDB HBCDG #>   Denmark       .   105   2562    617   1107  1034     .    93    89    89 #>   Estonia       .    26     63      .     18     .     1    21    21    21 #>   Finland       .   109   1006    309    558     .     .    70    70    70 #>   Germany       .    14    805    345    910   156    10     1     1     1 #>   Latvia        6     .    429      .      6     .     2     2     2     2 #>   Lithuania     .    12     51      .      .     4    12    12    12    12 #>   Poland        .     .   1702    380      .    18   620     .     .     . #>   Sweden        .   425   5781   3843      5    31  1957     .     .     . #>            determinand #> country        HG  IMPS  INTS LIPIDWT% LNMEA N-PFOS  OCDF    PB   PCB  PFOS #>   Denmark    2370   813  4718        .  1878      .     .  1782     .   102 #>   Estonia     175     .     .      156     .      .    26    98     .    22 #>   Finland    1412     .     .        .   697      .   109   779    28   164 #>   Germany     918     .     .        .  2151      .    14   770     .    12 #>   Latvia      294     .     .        .   267      .     6   170     .     4 #>   Lithuania   103     .     .       31    17      .    12    96     .    12 #>   Poland     1429     .     .      909  2538      .     .  1411     .   532 #>   Sweden     3279     .     .        . 12673    282     2  2834     .   241 #>            determinand #> country     PYR1OH   SCB  SCB7 SUM_PCB SUM_PCDD_PCDF SUM_PCDD_PCDF_PCB  TCDD #>   Denmark        .     .     .       .             .                 .   105 #>   Estonia        .    10     .       .             .                 .    26 #>   Finland        .     .   181       .             .                 .   109 #>   Germany     1311     .     .       .             .                 .    14 #>   Latvia         .     .     .       .             .                 .     6 #>   Lithuania      .     .     .      18            32                32     7 #>   Poland        54     .     .       .             .                 .     . #>   Sweden         .     .     .       .             .                 .   585 #>            determinand #> country       VDS  VDSI #>   Denmark    3273    76 #>   Estonia       .     . #>   Finland       .     . #>   Germany       .     . #>   Latvia        .     . #>   Lithuania     .     . #>   Poland        .     . #>   Sweden     8942   298  wk %>%   with(table(country, year)) %>%   print(zero.print = \".\") #>            year #> country     1979 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 #>   Denmark      .    .    .    .    .    .    .    .    .    .    .    .    . #>   Estonia      .    .    .    .    .    .    .    .    .    .    .    .    . #>   Finland     13   14   14   44   39   49   59   60   73  163   92  108   81 #>   Germany      .    .    .    .    .    .    .    .    .    .    .    .    . #>   Latvia       .    .    .    .    .    .    .    .    .    .    .    .    . #>   Lithuania    .    .    .    .    .    .    .    .    .    .    .    .    . #>   Poland       .    .    .    .    .    .    .    .    .    .    .    .    . #>   Sweden       .    .    .    .    .    .    .    .    .    .    .    .    . #>            year #> country     1993 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 #>   Denmark      .    .    .  300 1232  893  980 1646 1475 1624 1331  993 1012 #>   Estonia      .    .    .    .    .    .    .    .    .    .    4  108  126 #>   Finland    108   79   81   28  905  909  234  369  450  142  144  571  576 #>   Germany      .    .    .    .  110  209  211   81   96  110    .  159  156 #>   Latvia       .    .    .    .    .    .    2   37  120    .    .    .   44 #>   Lithuania    .    .    .    .    .    .    .    .    .    .    .    .    . #>   Poland       .    .    .    .  284  241  315  318  307  280  785  785  785 #>   Sweden       .    .    . 1663 2049 2235 2148 2413 2180 2720 2446 2439 2193 #>            year #> country     2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 #>   Denmark   1034 1540 2442 1306 3732 1789 3208 1546  585  793 1132 1107  965 #>   Estonia     84   14    .    .  276  368  296  246  247    .   54  235  303 #>   Finland    557  320  317  371 1019 1382  439 1451  366 1683   47  410 1269 #>   Germany    839  545 1372 1237 1118 1063 1623 1526 1602  602  915  500  446 #>   Latvia      67    .    .    .  143   91  149   76   45   85  160  164  125 #>   Lithuania    8    .   12   21   37   73   58   40  246  353    8   40   24 #>   Poland     525  525  525  525  525 1226 1428 1700 1588 1600 1590 1596 1639 #>   Sweden    2404 3544 5325 4670 5447 5395 5192 4562 1492 4559 4892 5227 4920 #>            year #> country     2020 2021 #>   Denmark   1151  603 #>   Estonia    400  336 #>   Finland   1023  743 #>   Germany    859  415 #>   Latvia     368    . #>   Lithuania   32    . #>   Poland    1824 1898 #>   Sweden    4635  972"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"finland---pfos-fatwt","dir":"Articles","previous_headings":"Biota > Duplicate records","what":"Finland - PFOS, FATWT%","title":"HELCOM","text":"PFOS FATWT% records Finland 2014 2015 appear duplicated (see ). first retained. (one set FATWT% records differ, kept now - wonder whether one actually MU.)","code":"wk <- biota_data$data %>%   filter(     country == \"Finland\",     year >= 2014   ) %>%   group_by(sub.sample, determinand, matrix) %>%   filter(n() >= 2) %>%   ungroup()  wk %>%   select(country, year, station_name, sub.sample, determinand, matrix, replicate, value) %>%   arrange(sub.sample, determinand, replicate) %>%   as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\") wk_rep <- wk$replicate  wk_keep <- wk %>%    select(sub.sample, matrix, determinand, replicate, value) %>%   arrange(replicate) %>%   distinct(sub.sample, matrix, determinand, value, .keep_all = TRUE) %>%   pull(replicate)  wk_drop <- setdiff(wk_rep, wk_keep)  biota_data$data <- filter(   biota_data$data,   !replicate %in% wk_drop )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"sweden---dioxins","dir":"Articles","previous_headings":"Biota > Duplicate records","what":"Sweden - dioxins","title":"HELCOM","text":"dioxin measurements Sweden 2009 2011 submitted wet lipid basis. summarised relevant stations (data last six monitoring years). ‘duplicates’ interchangeable, retained measurements lipid basis.","code":"get_relevant_biota <- function() {   biota_data$data %>%      filter(!is.na(station_name)) %>%     group_by(station_name) %>%     filter(any(year >= 2016)) %>%     ungroup() }  relevant_biota <- get_relevant_biota()  wk <- relevant_biota %>%    filter(pargroup %in% c(\"OC-DX\", \"O-BR\", \"OC-CB\")) %>%   group_by(sub.sample, matrix, determinand) %>%   filter(all(c(\"L\", \"W\") %in% basis)) %>%   ungroup() %>%   arrange(country, station_name, year, determinand, sub.sample, basis)  wk %>%   mutate(across(where(is.character), factor)) %>%   summary() #>                           indicator      ges_matrix     country     #>  dl-PCBs and dioxins and furans:2432   Primary:2432   Sweden:2432   #>                                                                     #>                                                                     #>                                                                     #>                                                                     #>                                                                     #>                                                                     #>        mprog       rlabo                    HELCOM_subbasin   HELCOM_L3   #>  CEMP~COMB: 128   SERI:2432   Bothnian Sea          :576    6      :448   #>  COMB     :2304               Bornholm Basin        :384    2      :384   #>                               Bothnian Bay          :384    SEA-007:384   #>                               Western Gotland Basin :320    4      :256   #>                               Northern Baltic Proper:256    SEA-010:256   #>                               The Quark             :256    9      :128   #>                               (Other)               :256    (Other):576   #>    HELCOM_L4                submitted.station    sd_code     #>  SEA-007:384   Ängskärsklubb         : 256    6140   : 256   #>  SWE-016:384   Utlängan              : 256    6226   : 256   #>  SEA-010:256   Holmöarna             : 192    5809   : 192   #>  SWE-022:256   Abbekås               : 128    11188  : 128   #>  SWE-021:192   Bothnian Sea off shore: 128    11189  : 128   #>  SEA-001:128   Byxelkrok             : 128    5803   : 128   #>  (Other):832   (Other)               :1344    (Other):1344   #>                    sd_name      station_code                  station_name  #>  Ängskärsklubb         : 256   6140   : 256   Ängskärsklubb         : 256   #>  Utlängan              : 256   6226   : 256   Utlängan              : 256   #>  Holmöarna             : 192   5809   : 192   Holmöarna             : 192   #>  Abbekås               : 128   11188  : 128   Abbekås               : 128   #>  Bothnian Sea off shore: 128   11189  : 128   Bothnian Sea off shore: 128   #>  Byxelkrok             : 128   5803   : 128   Byxelkrok             : 128   #>  (Other)               :1344   (Other):1344   (Other)               :1344   #>       year              date      sample_latitude sample_longitude purpm    #>  Min.   :2009   11/05/2009: 128   Min.   :55.32   Min.   :11.83    T:2432   #>  1st Qu.:2009   12/10/2010: 128   1st Qu.:57.22   1st Qu.:15.78             #>  Median :2009   01/10/2010:  64   Median :60.05   Median :18.16             #>  Mean   :2009   04/10/2010:  64   Mean   :60.13   Mean   :18.14             #>  3rd Qu.:2010   06/09/2010:  64   3rd Qu.:63.53   3rd Qu.:20.50             #>  Max.   :2010   07/08/2009:  64   Max.   :65.76   Max.   :22.88             #>                 (Other)   :1920                                             #>   finfl                   species       sex        n_individual    pargroup    #>  NA's:2432   Clupea harengus  :2240   F   :1280   Min.   : 7.00   OC-DX:2432   #>              Perca fluviatilis: 192   M   :1120   1st Qu.:12.00                #>                                       NA's:  32   Median :12.00                #>                                                   Mean   :11.78                #>                                                   3rd Qu.:12.00                #>                                                   Max.   :12.00                #>                                                                                #>   determinand   matrix    basis       unit          value           censoring   #>  CDD1N  : 152   MU:2432   L:1216   ng/kg:  76   Min.   :  0.00047   D   : 336   #>  CDD4X  : 152             W:1216   pg/g :2356   1st Qu.:  0.07486   NA's:2096   #>  CDD6P  : 152                                   Median :  0.69600               #>  CDD6X  : 152                                   Mean   :  4.14714               #>  CDD9X  : 152                                   3rd Qu.:  3.10000               #>  CDDO   : 152                                   Max.   :150.00000               #>  (Other):1520                                                                   #>   vflag      limit_detection    limit_quantification  uncertainty   #>  NA's:2432   Min.   : 0.00047   Min.   : NA          Min.   : NA    #>              1st Qu.: 0.07486   1st Qu.: NA          1st Qu.: NA    #>              Median : 0.20000   Median : NA          Median : NA    #>              Mean   : 0.40771   Mean   :NaN          Mean   :NaN    #>              3rd Qu.: 0.60970   3rd Qu.: NA          3rd Qu.: NA    #>              Max.   :15.00000   Max.   : NA          Max.   : NA    #>                                 NA's   :2432         NA's   :2432   #>  unit_uncertainty  alabo      method_analysis  smtyp       dcflgs     #>  NA's:2432        UMSC:2432   GC-MS:2432      NA's:2432   NA's:2432   #>                                                                       #>                                                                       #>                                                                       #>                                                                       #>                                                                       #>                                                                       #>      smpno             subno          qalink         replicate        #>  34649  :  64   1022010229:  32   Min.   :516368   Min.   :47976502   #>  34650  :  64   1070810719:  32   1st Qu.:516375   1st Qu.:47984157   #>  34651  :  64   1072010731:  32   Median :516383   Median :47985670   #>  34652  :  64   1098710998:  32   Mean   :516416   Mean   :47988683   #>  34653  :  64   1099911010:  32   3rd Qu.:516458   3rd Qu.:47994241   #>  34654  :  64   1125311259:  32   Max.   :516466   Max.   :47996074   #>  (Other):2048   (Other)   :2240                                       #>    sub.sample       sample       tblspotid          upload      subseries   #>  3741770:  32   2112871:  64   Min.   :367894   Min.   :10335   NA's:2432   #>  3741771:  32   2112872:  64   1st Qu.:367929   1st Qu.:10335               #>  3741784:  32   2112873:  64   Median :367950   Median :10335               #>  3741785:  32   2112875:  64   Mean   :367952   Mean   :10335               #>  3741798:  32   2112876:  64   3rd Qu.:367982   3rd Qu.:10336               #>  3741799:  32   2112877:  64   Max.   :368010   Max.   :10336               #>  (Other):2240   (Other):2048  wk_id <- wk %>%    filter(basis == \"W\") %>%   pull(replicate)  biota_data$data <- filter(   biota_data$data,    !replicate %in% wk_id )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"germany---fatwt","dir":"Articles","previous_headings":"Biota > Duplicate records","what":"Germany - FATWT%","title":"HELCOM","text":"FATWT% records Germany appear duplicated (see ). One set uncertainty measurements unusually small, accept (either uncertainty reported percentage, U2 ten percent value).","code":"wk <- biota_data$data %>%   filter(     country == \"Germany\",      determinand %in% \"FATWT%\"   ) %>%   group_by(sub.sample, determinand, matrix) %>%   filter(n() >= 2) %>%   ungroup()    wk %>%    select(year, station_name, sub.sample, determinand, matrix,           replicate, value, uncertainty, unit_uncertainty) %>%    arrange(year, sub.sample, determinand, replicate) %>%   as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\") wk_rep <- wk$replicate  wk_keep <- wk %>%    filter(     unit_uncertainty == \"%\" |       100 * uncertainty / value > 5     ) %>%    pull(replicate)  stopifnot(2 * length(wk_keep) == length(wk_rep))  wk_drop <- setdiff(wk_rep, wk_keep)  biota_data$data <- filter(   biota_data$data,    !replicate %in% wk_drop )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"pcbs-and-dioxins","dir":"Articles","previous_headings":"Biota","what":"PCBs and dioxins","title":"HELCOM","text":"’s summary determinands submitted PCBs, dioxins furans. summed values need accounted . year. PCB ambiguous, deprecated old SCB ambiguous, deprecated occurs 2006 SCB7 relevant combines non-planar CBs dioxin-like CB118 (also pretty old) SUM_PCB, SUM_PCDD_PCDF SUM_PCDD_PCDF_PCB , think, Lithuanian food safety data made special arrangements last time; however, data last six monitoring years combinations, individual congeners stations; data therefore fall assessment assessment code doesn’t recognise ad-hoc determinands without modification, lot easier get rid .","code":"wk <- biota_data$data %>%   filter(     !is.na(station_name),     pargroup %in% c(\"OC-CB\", \"OC-DX\", \"OC-DX~OC-CB\")   )  table(wk$determinand) #>  #>             CB101             CB105             CB110             CB114  #>              5963              1643               411               605  #>             CB118             CB122             CB123             CB126  #>              6469                48               605               655  #>             CB128             CB138         CB138+163             CB141  #>               593              5464               503                69  #>             CB149             CB151             CB153             CB156  #>               523               246              5967              1646  #>             CB157             CB167             CB169             CB170  #>               755               685               736               587  #>              CB18             CB180             CB183             CB187  #>                69              5962                69               291  #>             CB189             CB194             CB206             CB209  #>               605                76                69                75  #>              CB28              CB31              CB33              CB44  #>              5788               545                69               246  #>              CB47              CB49              CB51              CB52  #>                69               315                48              5826  #>              CB60              CB66              CB74              CB77  #>                48               117                69               735  #>              CB81              CB99             CDD1N             CDD4X  #>               604               316               750               751  #>             CDD6P             CDD6X             CDD9X              CDDO  #>               750               751               748               726  #>             CDDSN             CDDSP             CDDST             CDDSX  #>                 6                 6                 6                 6  #>             CDF2N             CDF2T             CDF4X             CDF6P  #>               830               756               750               749  #>             CDF6X             CDF9P             CDF9X             CDFDN  #>               751               750               750               247  #>              CDFO             CDFP2             CDFSN             CDFSP  #>               605               663                 6                 6  #>             CDFST             CDFSX             CDFX1              OCDF  #>                 6                 6               666               148  #>               PCB               SCB              SCB7           SUM_PCB  #>                28                10               181                18  #>     SUM_PCDD_PCDF SUM_PCDD_PCDF_PCB              TCDD  #>                32                32               751 wk_id <- c(\"PCB\", \"SCB\", \"SCB7\", \"SUM_PCB\", \"SUM_PCDD_PCDF\", \"SUM_PCDD_PCDF_PCB\")  wk %>%   filter(determinand %in% wk_id) %>%   with(table(determinand, year)) %>%   print(zero.print = \".\") #>                    year #> determinand         1979 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 #>   PCB                  2    2    2    4    6    4    4    4    .    .    .    . #>   SCB                  .    .    .    .    .    .    .    .    .    .    .    . #>   SCB7                 .    .    .    .    .    .    .    .    6   15    8    8 #>   SUM_PCB              .    .    .    .    .    .    .    .    .    .    .    . #>   SUM_PCDD_PCDF        .    .    .    .    .    .    .    .    .    .    .    . #>   SUM_PCDD_PCDF_PCB    .    .    .    .    .    .    .    .    .    .    .    . #>                    year #> determinand         1992 1993 1995 1996 1998 1999 2006 2010 2011 2012 2013 2014 #>   PCB                  .    .    .    .    .    .    .    .    .    .    .    . #>   SCB                  .    .    .    .    .    .   10    .    .    .    .    . #>   SCB7                 6    8    6    6   60   58    .    .    .    .    .    . #>   SUM_PCB              .    .    .    .    .    .    .    .    .    5    4    4 #>   SUM_PCDD_PCDF        .    .    .    .    .    .    .    5    5    8    5    4 #>   SUM_PCDD_PCDF_PCB    .    .    .    .    .    .    .    5    5    8    5    4 #>                    year #> determinand         2015 #>   PCB                  . #>   SCB                  . #>   SCB7                 . #>   SUM_PCB              5 #>   SUM_PCDD_PCDF        5 #>   SUM_PCDD_PCDF_PCB    5 wk_check <- wk %>%   group_by(station_name) %>%   filter(any(year >= 2016)) %>%   ungroup()  wk_id2 <- c(\"SUM_PCB\", \"SUM_PCDD_PCDF\", \"SUM_PCDD_PCDF_PCB\")  if (any(wk_id2 %in% wk_check$determinand)) {   stop(\"have current summed Lithuanian data\") }  biota_data$data <- filter(   biota_data$data,    !determinand %in% wk_id )"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"sweden---pcbs","dir":"Articles","previous_headings":"Biota > Replicate measurements","what":"Sweden - PCBs","title":"HELCOM","text":"Swedish PCBs (predominantly CB118) measured twice individual, presume standard set PCB reporting dioxin reporting. number measurements affected, corresponding analytical laboratory (restricted relevant stations data last six monitoring years). analtyical laboratories also measured dioxins sub-samples. Sensible decision seems retain CB118 measurements analytical laboratory UMSC, since part analysis suite. leaves two replicates six PCBs single sub.sample. appear genuine replicates. leave , code select one analysis.","code":"relevant_biota <- get_relevant_biota()  wk <- relevant_biota %>%   filter(     pargroup %in% \"OC-CB\",     country == \"Sweden\"   ) %>%   group_by(sub.sample, matrix, determinand) %>%   filter(n() >= 2) %>%   ungroup() %>%   as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\")  wk %>%   with(table(determinand, alabo)) #> Error in eval(substitute(expr), data, enclos = parent.frame()): invalid 'envir' argument of type 'character' wk_id <- wk$sub.sample #> Error in wk$sub.sample: $ operator is invalid for atomic vectors  relevant_biota %>%   filter(     sub.sample %in% wk_id,     pargroup == \"OC-DX\"   ) %>%   with(table(determinand, alabo)) #> < table of extent 0 x 0 > wk_id <- wk %>%   filter(!alabo %in% \"UMSC\") %>%   pull(replicate) #> Error in UseMethod(\"filter\"): no applicable method for 'filter' applied to an object of class \"knitr_kable\"  biota_data$data <- filter(   biota_data$data,   !replicate %in% wk_id )  get_relevant_biota() %>%   filter(     pargroup %in% \"OC-CB\",     country == \"Sweden\"   ) %>%    group_by(sub.sample, matrix, determinand) %>%   filter(n() >= 2) %>%   ungroup() %>%   as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\")"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"poland-pcb-2014-data","dir":"Articles","previous_headings":"Biota","what":"Poland PCB 2014 data","title":"HELCOM","text":"following plot shows concentrations CB153 station time. measurements fish muscle units ug/kg ww. species varies stations, consistent within stations. strange things going , results 2014 (red) particularly strange deleted (PCB data year consistency.) plot chunk helcom-data-adjust-bio_CB153_1 data look like without 2014 values. Many less-values implausibly low relative bulk data (see LWLA LKOL 2013, many stations 2005 2008), data scrutiny. PCBs might exhibit similar features, hasn’t investigated. plot chunk helcom-data-adjust-bio_CB153_2","code":"biota_data$data <- mutate(   biota_data$data,    .id = country == \"Poland\" & pargroup == \"OC-CB\" )  wk_data <- biota_data$data %>%   filter(.id & determinand == \"CB153\") %>%   mutate(concentration = convert_units(value, unit, \"ug/kg\"))  stopifnot(   wk_data$matrix == \"MU\",   wk_data$basis == \"W\" )  xyplot(   concentration ~ year | station_name,   data = wk_data,   scales = list(alternating = FALSE, y = list(log = TRUE, equispaced.log = FALSE)),   panel = function(x, y, subscripts) {     col = if_else(wk_data$year[subscripts] == 2014, \"red\", \"blue\")     lpoints(x, y, pch = 16, col = col)   } ) biota_data$data <- filter(   biota_data$data,    !(.id & year == 2014) )  wk_data <- biota_data$data %>%   filter(.id & determinand == \"CB153\") %>%   mutate(concentration = convert_units(value, unit, \"ug/kg\"))  biota_data$data$'.id' <- NULL  xyplot(   concentration ~ year | station_name,   data = wk_data,   scales = list(alternating = FALSE, y = list(log = TRUE, equispaced.log = FALSE)),   panel = function(x, y, subscripts) {     col = if_else(wk_data$year[subscripts] == 2014, \"red\", \"blue\")     lpoints(x, y, pch = 16, col = col)   } )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"strange-censoring-values","dir":"Articles","previous_headings":"Biota","what":"Strange censoring values","title":"HELCOM","text":"following data relevant stations (data last six years) censoring = “>”, unusual. German data appear well limits detection, “>” removed. Swedish data appear values limit detection replaced censoring = “D”.","code":"get_relevant_biota() %>%   filter(grepl(\">\", censoring)) %>%   select(country, year, determinand, value, censoring, limit_detection, limit_quantification) %>%   arrange(country, year, determinand) %>%   as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\") biota_data$data <- mutate(   biota_data$data,    .id = grepl(\">\", censoring),   censoring = if_else(.id & country == \"Germany\", NA_character_, censoring),   censoring = if_else(.id & country == \"Sweden\", \"D\", censoring),   .id = NULL )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"matrix-muep","dir":"Articles","previous_headings":"Biota","what":"Matrix MU&EP","title":"HELCOM","text":"’s summary matrices species ‘relevant’ stations (data last six monitoring years). contaminant data BI, POP, SH WO, can ignore current discussion. Thus, contaminant data MU LI (fish) SB (shellfish) apart measurements MU&EP. Perch Finland also MU measurements. need teased apart. ’s summary number records perch Finland matrix year. Muscle skin measurements start 2014. matrices CD, HG, PB, PFOS everything else year. Routes forward: Cadmium lead: look liver drop single MU&EP measurement (extraction table mentions LI MU metals) Mercury: muscle, good PFOS: lipid adjustment doesn’t make sense combine MU MU&EP measurements time series appears systematic difference concentration matrices (see ); select MU&EP recent data (Emmi, 16 August); note liver muscle data drop automatically data last six monitoring years Others (organics): combine MU&EP MU measurements time series following lipid normalisation; time series labelled matrix MU&EP summary file since recent measurements","code":"relevant_biota <- get_relevant_biota()  relevant_biota %>%   with(table(species, matrix)) %>%   print(zero.print = \".\") #>                     matrix #> species                 BI    LI    MU MU&EP   POP    SB    SH    WO #>   Buccinum undatum       .     .     .     .     .  2400     .     9 #>   Clupea harengus       39  9399 59591     .     .     .     .  4443 #>   Gadus morhua         275  7060  1066     .     .     .     .   840 #>   Hinia reticulata       .     .     .     .     .   684     .     . #>   Limanda limanda      231  2307   279     .     .     .     .   501 #>   Limecola balthica      .     .     .     .     .    12     .     . #>   Littorina littorea     .     .     .     .     .   379     .     . #>   Macoma balthica        .     .     .     .     .    26     .     . #>   Mytilus edulis         .     .     .     .     .  7191   925   147 #>   Neptunea antiqua       .     .     .     .     .   443     .     6 #>   Perca fluviatilis     16  2421 12202  2423     .     .     .  1253 #>   Peringia ulvae         .     .     .     .    94  6491  6055     . #>   Platichthys flesus   338  4964  5923     .     .     .     .   907 #>   Zoarces viviparus      .   858  4599     .     .     .     .   269 relevant_biota %>%   filter(matrix %in% c(\"BI\", \"POP\", \"SH\", \"WO\")) %>%   with(table(determinand, matrix)) %>%   print(zero.print = \".\") #>             matrix #> determinand    BI  POP   SH   WO #>   %FEMALEPOP    .   94    .    . #>   LNMEA         .    . 6980 8360 #>   PYR1OH      899    .    .    . #>   VDSI          .    .    .   15 wk <- relevant_biota %>%   filter(     country == \"Finland\",     species == \"Perca fluviatilis\"   )  wk %>%   with(table(matrix, year)) %>%   print(zero.print = \".\") #>        year #> matrix  2011 2012 2014 2015 2016 2019 2020 2021 #>   LI       .    .    2    3    4    8   12   10 #>   MU      51  321    9   26   40   89   63   10 #>   MU&EP    .    .   12  209  595  632  540  435 wk %>%   filter(determinand != \"FATWT%\") %>%   mutate(     determinand = if_else(       determinand %in% c(\"CD\", \"PB\", \"HG\", \"PFOS\"),       determinand,       \"other\"     )   ) %>%   with(table(matrix, year, determinand)) %>%   print(zero.print = \".\") #> , , determinand = CD #>  #>        year #> matrix  2011 2012 2014 2015 2016 2019 2020 2021 #>   LI       .    .    .    .    2    4    6    5 #>   MU       .    .    .    .    .    .    .    . #>   MU&EP    .    .    .    .    .    1    .    . #>  #> , , determinand = HG #>  #>        year #> matrix  2011 2012 2014 2015 2016 2019 2020 2021 #>   LI       .    .    .    .    .    .    .    . #>   MU      15   55    5   20   40   89   63   10 #>   MU&EP    .    .    .    .    .    .    .    . #>  #> , , determinand = other #>  #>        year #> matrix  2011 2012 2014 2015 2016 2019 2020 2021 #>   LI       .    .    .    .    .    .    .    . #>   MU      34  248    .    .    .    .    .    . #>   MU&EP    .    .    6  192  575  610  528  425 #>  #> , , determinand = PB #>  #>        year #> matrix  2011 2012 2014 2015 2016 2019 2020 2021 #>   LI       .    .    .    .    2    4    6    5 #>   MU       .    .    .    .    .    .    .    . #>   MU&EP    .    .    .    .    .    1    .    . #>  #> , , determinand = PFOS #>  #>        year #> matrix  2011 2012 2014 2015 2016 2019 2020 2021 #>   LI       .    .    2    3    .    .    .    . #>   MU       .    2    2    3    .    .    .    . #>   MU&EP    .    .    2    3   10   10   12   10 wk %>%   filter(determinand == \"PFOS\") %>%   filter(matrix != \"LI\") %>%   group_by(station_name, year) %>%   filter(any(matrix %in% \"MU\")) %>%   ungroup() %>%   select(station_name, year, matrix, value) %>%   arrange(station_name, year, matrix) %>%   as.data.frame() %>%   knitr::kable(format = \"html\", table.attr = \"class=\\'datatable\\'\") biota_data$data <- biota_data$data %>%   mutate(     .id = country == \"Finland\" &       species == \"Perca fluviatilis\"   ) %>%   filter(     !(.id &       matrix == \"MU&EP\" &       determinand %in% c(\"CD\", \"PB\")     ),     !(.id &       matrix == \"MU\" &       determinand %in% c(\"PFOS\")     )   ) %>%   mutate(.id = NULL)"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"germany-station-issues","dir":"Articles","previous_headings":"Biota","what":"Germany station issues","title":"HELCOM","text":"data submitted station OMMVKHO (number samples year ), station station dictionary. However, station called KHO compatible co-ordinates, station relabelled KHO.","code":"biota_data$data <- mutate(   biota_data$data,   .id = country == \"Germany\" & submitted.station == \"OMMVKHO\" )  biota_data$data %>%   filter(.id) %>%   distinct(sample, year, .keep_all = TRUE) %>%   with(table(submitted.station, year)) #>                  year #> submitted.station 2017 2020 #>           OMMVKHO    1    2  wk_code <- get_station_code(\"KHO\", \"Germany\", biota_data$stations)  biota_data$data <- mutate(   biota_data$data,    station_name = if_else(.id, \"KHO\", station_name),   station_code = if_else(.id, wk_code, station_code),   .id = NULL )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"pyr1oh","dir":"Articles","previous_headings":"Biota","what":"PYR1OH","title":"HELCOM","text":"quick summary data. PAH metabolite units can concentration metabolite (ng/g similar), concentration relative bile pigments (e.g. ng g-1 a380-1). assessment consider metabolite concentrations. Delete concentration data relative bile pigments. summary data method analysis (important application EAC). Drop GRS data, part one-project (Ulrike, 2 September). left species country. Conventionally, separate time series modelled method analysis. However, assessment, remaining methods analysis regarded comparable (Ulrike, 15 August). labelled HPLC-FD summary file, since correspond bulk measurements Germany Poland. (coded main assessment file.)","code":"relevant_biota <- get_relevant_biota()  relevant_biota %>%    filter(determinand %in% \"PYR1OH\") %>%   with(table(species, year, country)) %>%   print(zero.print = \".\") #> , , country = Germany #>  #>                     year #> species              2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 #>   Clupea harengus       .   21    .    .    .    .    .    .    .    .    . #>   Gadus morhua          .    .    .    .   34    .   78    .   51   54   42 #>   Limanda limanda      60   11   12   10   15   17   21    .   19   19   14 #>   Perca fluviatilis     .    .    .    .    .    .    .    .    .    .    . #>   Platichthys flesus   99   23   28   34    .   58   59    .   20    .    . #>                     year #> species              2020 2021 #>   Clupea harengus       .    . #>   Gadus morhua         16    . #>   Limanda limanda      33    . #>   Perca fluviatilis     .    . #>   Platichthys flesus    .    . #>  #> , , country = Poland #>  #>                     year #> species              2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 #>   Clupea harengus       .    .    .    2    .    2    2    2    2    2    2 #>   Gadus morhua          .    .    .    .    .    .    .    .    .    .    . #>   Limanda limanda       .    .    .    .    .    .    .    .    .    .    . #>   Perca fluviatilis     .    .    .    .    .    2    2    2    2    2    2 #>   Platichthys flesus    .    .    .    1    .    1    1    2    2    2    2 #>                     year #> species              2020 2021 #>   Clupea harengus       2    2 #>   Gadus morhua          .    . #>   Limanda limanda       .    . #>   Perca fluviatilis     2    2 #>   Platichthys flesus    3    3 relevant_biota %>%   filter(determinand %in% \"PYR1OH\") %>%   with(table(species, unit)) %>%   print(zero.print = \".\") #>                     unit #> species              ng g-1 a380-1 ng g-1 a660-1 ng/g ng/ml ug/ml #>   Clupea harengus                .             .   25     2    12 #>   Gadus morhua                   .             .  275     .     . #>   Limanda limanda               20            20  191     .     . #>   Perca fluviatilis              .             .    4     .    12 #>   Platichthys flesus            33            33  261     1    10  biota_data$data <- filter(   biota_data$data,   !unit %in% c(\"ng g-1 a380-1 ng\", \"ng g-1 a660-1\") ) get_relevant_biota() %>%   filter(determinand %in% \"PYR1OH\") %>%   with(table(method_analysis, year)) %>%   print(zero.print = \".\") #>                 year #> method_analysis  2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 #>   GC-MS-MS          .    .    .    .    .    .    .    .    .    .    .    . #>   GRS             106    .    .    .    .    .    .    .    .    .    .    . #>   HPLC-ESI-MS-MS    .    .    .    .    .    .    .    .    .    .    .    7 #>   HPLC-FD           .   55   40   47   49   80  163    6   96   79   62   49 #>                 year #> method_analysis  2021 #>   GC-MS-MS          7 #>   GRS               . #>   HPLC-ESI-MS-MS    . #>   HPLC-FD           .  biota_data$data <- filter(   biota_data$data,    !(determinand %in% \"PYR1OH\" & method_analysis %in% \"GRS\") ) get_relevant_biota() %>%   filter(determinand %in% \"PYR1OH\") %>%   with(table(method_analysis, year, country)) %>%   print(zero.print = \".\") #> , , country = Germany #>  #>                 year #> method_analysis  2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>   GC-MS-MS          .    .    .    .    .    .    .    .    .    .    .    . #>   HPLC-ESI-MS-MS    .    .    .    .    .    .    .    .    .    .    .    . #>   HPLC-FD          55   40   44   49   75  158    .   90   73   56   49    . #>  #> , , country = Poland #>  #>                 year #> method_analysis  2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>   GC-MS-MS          .    .    .    .    .    .    .    .    .    .    .    7 #>   HPLC-ESI-MS-MS    .    .    .    .    .    .    .    .    .    .    7    . #>   HPLC-FD           .    .    3    .    5    5    6    6    6    6    .    ."},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"sbde6-1","dir":"Articles","previous_headings":"Biota","what":"SBDE6","title":"HELCOM","text":"info, PBDE measurements country (filtered stations monitored last six years). simplicity, ’ve restricted last twelve years. historic data Denmark Sweden lost computing sum six PBDEs. Note HOLAS2 assessed SBDE4 = BDE47 + BDE99 + BD100 + BD153, many BDE28 BD154 measurements, predominantly Denmark Sweden, missing; far less issue now.","code":"wk <- biota_data$data %>%   filter(grepl(\"BD\", determinand)) %>%   group_by(station_name) %>%   filter(any(year >= 2016)) %>%   ungroup()  wk %>% filter(year >= 2010) %>%   with(table(determinand, year, country)) %>%   print(zero.print = \".\") #> , , country = Denmark #>  #>            year #> determinand 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>       BD100    .    6    8    7    8    3    7   21   14   14   13    8 #>       BD153    .    6    8    7    8    3    7   20   14   14   13    8 #>       BD154    .    6    8    7    8    3    7   21   14   14   13    8 #>       BDE28    .    .    .    .    8    3    6   20   14   14   13    8 #>       BDE47    .    6    4    4    3    2    7   20   14   14   13    8 #>       BDE99    .    6    6    7    8    2    7   21   14   14   13    8 #>  #> , , country = Estonia #>  #>            year #> determinand 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>       BD100    .    .    .    .    .    .    .    1    5    6    8    7 #>       BD153    .    .    .    .    .    .    .    1    5    6    8    7 #>       BD154    .    .    .    .    .    .    .    1    5    6    8    7 #>       BDE28    .    .    .    .    .    .    .    1    5    6    8    7 #>       BDE47    .    .    .    .    .    .    .    1    5    6    8    7 #>       BDE99    .    .    .    .    .    .    .    1    5    6    8    7 #>  #> , , country = Finland #>  #>            year #> determinand 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>       BD100    .    4    8    .   17    3   19    .    5   18   20   16 #>       BD153    .    4    8    .   17    3   19    .    5   18   20   16 #>       BD154    .    4    8    .   17    3   19    .    5   18   20   16 #>       BDE28    .    4    8    .   17    3   19    .    5   18   20   16 #>       BDE47    .    4    8    .   17    3   19    .    5   18   20   16 #>       BDE99    .    4    8    .   17    3   19    .    5   18   20   16 #>  #> , , country = Germany #>  #>            year #> determinand 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>       BD100    .    .    .    .    .    .    .    1    2    2    4    2 #>       BD153    .    .    .    .    .    .    .    1    2    2    4    2 #>       BD154    .    .    .    .    .    .    .    1    2    2    4    2 #>       BDE28    .    .    .    .    .    .    .    1    2    2    4    2 #>       BDE47    .    .    .    .    .    .    .    1    2    2    4    2 #>       BDE99    .    .    .    .    .    .    .    1    2    2    4    2 #>  #> , , country = Latvia #>  #>            year #> determinand 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>       BD100    .    .    .    .    .    .    .    2    .    .    4    . #>       BD153    .    .    .    .    .    .    .    2    .    .    4    . #>       BD154    .    .    .    .    .    .    .    2    .    .    4    . #>       BDE28    .    .    .    .    .    .    .    2    .    .    4    . #>       BDE47    .    .    .    .    .    .    .    2    .    .    4    . #>       BDE99    .    .    .    .    .    .    .    2    .    .    4    . #>  #> , , country = Lithuania #>  #>            year #> determinand 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>       BD100    .    .    .    .    .    3    7    .    .    .    .    . #>       BD153    .    .    .    .    .    3    7    .    .    .    .    . #>       BD154    .    .    .    .    .    3    7    .    .    .    .    . #>       BDE28    .    .    .    .    .    3    7    .    .    .    .    . #>       BDE47    .    .    .    .    .    3    7    .    .    .    .    . #>       BDE99    .    .    .    .    .    3    7    .    .    .    .    . #>  #> , , country = Poland #>  #>            year #> determinand 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>       BD100    .    .   34   34   54   54   64   64   64   64   74   74 #>       BD153    .    .   34   34   54   54   64   64   64   64   74   74 #>       BD154    .    .   34   34   54   54   64   64   64   64   74   74 #>       BDE28    .    .   34   34   54   54   64   64   64   64   74   74 #>       BDE47    .    .   34   34   54   54   64   64   64   64   74   74 #>       BDE99    .    .   34   34   54   54   64   64   64   64   74   74 #>  #> , , country = Sweden #>  #>            year #> determinand 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>       BD100  102  106  106  106   94    .   92  104  100   86   88    . #>       BD153  102  106  106  106   94    .   92  104  100   86   88    . #>       BD154    .    .    .    .    .    .   92  104   98   85   88    . #>       BDE28    .    .    .    .    .    .   92  104  100   86   88    . #>       BDE47  102  106  106  106   94    .   92  104  100   86   88    . #>       BDE99  102  106  106  106   94    .   92  104   99   86   88    ."},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"teq-dfp","dir":"Articles","previous_headings":"Biota","what":"TEQ DFP","title":"HELCOM","text":"PCB dioxin measurements contribute TEQ DFP country (since 2010). Estonia, Finland, Germany Lithuania largely missing CDFO, Germany missing three measurements CDFP2. However, turns countries submitted similar (identical?) compounds related codes. OCDF recoded CDFO CDFDN recoded CDFP2.","code":"wk <- biota_data$data %>%   filter(     determinand %in% names(info_TEQ)   ) %>%   group_by(sub.sample) %>%   filter(any(pargroup %in% \"OC-DX\")) %>%   ungroup() %>%   group_by(station_name) %>%   filter(any(year >= 2016)) %>%   ungroup()  wk %>%   filter(year >= 2010) %>%   with(table(determinand, country)) %>%   print(zero.print = \".\") #>            country #> determinand Denmark Estonia Finland Germany Latvia Lithuania Sweden #>       CB105      74      26      63      14      6        10    452 #>       CB118      73      26      63      17      6        10    731 #>       CB126      70      26      63      14      6        10    415 #>       CB156      74      26      63      14      6        10    452 #>       CB157      34      26      63      14      6        10    452 #>       CB167      34      26      63      14      6        10    452 #>       CB169      71      26      63      14      6        10    452 #>       CB77       70      26      63      14      6        10    452 #>       CB81       34      26      63      14      6        10    415 #>       CDD1N      91      26     100      14      .        10    452 #>       CDD4X      92      26     100      14      .        10    452 #>       CDD6P      91      26     100      14      .        10    452 #>       CDD6X      92      26     100      14      .        10    452 #>       CDD9X      91      26     100      14      .         8    452 #>       CDDO       74      26     100      14      6         7    452 #>       CDF2N      91      26     100      14      .        10    452 #>       CDF2T      91      26     100      14      6        10    452 #>       CDF4X      91      26     100      14      .        10    452 #>       CDF6P      90      26     100      14      .        10    452 #>       CDF6X      92      26     100      14      .        10    452 #>       CDF9P      91      26     100      14      .        10    452 #>       CDF9X      91      26     100      14      .        10    452 #>       CDFO       90       .       .       .      .         .    452 #>       CDFP2      91      26     100      11      .        10    415 #>       CDFX1      91      26     100      14      .        10    415 #>       TCDD       91      26     100      14      6         7    452 wk <- biota_data$data %>%   filter(     pargroup %in% \"OC-DX\",     !determinand %in% names(info_TEQ),     country %in% c(\"Estonia\", \"Finland\", \"Germany\", \"Lithuania\")   ) %>%   group_by(station_name) %>%   filter(any(year >= 2016)) %>%   ungroup()  wk %>% filter(year >= 2010) %>%   with(table(determinand, country)) %>%   print(zero.print = \".\") #>            country #> determinand Estonia Finland Germany Lithuania #>       CDFDN       .       .       3         . #>       OCDF       26     100      14        10  biota_data$data <- mutate(   biota_data$data,   determinand = if_else(     country %in% c(\"Estonia\", \"Finland\", \"Germany\", \"Lithuania\") &       determinand %in% \"OCDF\",     \"CDFO\",     determinand   ),   determinand = if_else(     country %in% \"Germany\" & determinand %in% \"CDFDN\",     \"CDFP2\",     determinand   ) )"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"data-summary-3","dir":"Articles","previous_headings":"Biota > Imposex","what":"Data summary","title":"HELCOM","text":"summary imposex measurements species. Nassarius reticulatus equivalent Hinia reticulata combine (called Tritia nitida / reticulata assessment output). done , number measurements relevant stations (data last six years). assess VDS VDSI Buccinum, Hinia, Neptunea Peringia INTS Littorina. simple summary individual measurements.","code":"wk <- biota_data$data %>%   filter(     !is.na(station_name),     determinand %in% c(\"VDS\", \"VDSI\", \"INTS\", \"INTSI\", \"IMPS\", \"IMPSI\", \"PCI\")   )  wk %>%   with(table(species, determinand)) %>%   print(zero.print = \".\") #>                        determinand #> species                 IMPS INTS  VDS VDSI #>   Buccinum undatum       680  670 1525   40 #>   Hinia reticulata         . 1244 1394    . #>   Littorina littorea       . 2580    .    . #>   Nassarius reticulatus    .    . 2856   84 #>   Neptunea antiqua       133  121  280   31 #>   Nucella lapillus         .    .   21    5 #>   Peringia ulvae           .    . 6022  212 wk <- wk %>%   mutate(     species = recode(species, \"Nassarius reticulatus\" = \"Hinia reticulata\")   ) %>%   group_by(station_name, species) %>%   filter(any(year >= 2016)) %>%   ungroup()  wk %>%   with(table(species, determinand)) %>%   print(zero.print = \".\") #>                     determinand #> species              IMPS INTS  VDS VDSI #>   Buccinum undatum    259  424  859   28 #>   Hinia reticulata      .  112  206    . #>   Littorina littorea    .  379    .    . #>   Neptunea antiqua      1    3   30    1 #>   Peringia ulvae        .    . 5955  210 wk <- wk %>%   filter(     (determinand %in% c(\"VDS\", \"VDSI\") & !species %in% \"Littorina littorea\") |       species %in% \"Littorina littorea\"   )  wk %>%   with(table(species, determinand)) %>%   print(zero.print = \".\") #>                     determinand #> species              INTS  VDS VDSI #>   Buccinum undatum      .  859   28 #>   Hinia reticulata      .  206    . #>   Littorina littorea  379    .    . #>   Neptunea antiqua      .   30    1 #>   Peringia ulvae        . 5955  210  wk %>%   filter(determinand %in% c(\"VDS\", \"INTS\")) %>%   with(table(species, value, determinand)) %>%   print(zero.print = \".\") #> , , determinand = INTS #>  #>                     value #> species                 0    1    2    3 4 5 6 #>   Buccinum undatum      .    .    .    . . . . #>   Hinia reticulata      .    .    .    . . . . #>   Littorina littorea  227   75    8   69 . . . #>   Neptunea antiqua      .    .    .    . . . . #>   Peringia ulvae        .    .    .    . . . . #>  #> , , determinand = VDS #>  #>                     value #> species                 0    1    2    3    4    5    6 #>   Buccinum undatum    815   35    2    3    4    .    . #>   Hinia reticulata     37   55   13   47   54    .    . #>   Littorina littorea    .    .    .    .    .    .    . #>   Neptunea antiqua     28    1    .    .    1    .    . #>   Peringia ulvae     4243 1337  191   23   57   82   22"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"sweden---missing-zeros","dir":"Articles","previous_headings":"Biota > Imposex","what":"Sweden - missing zeros","title":"HELCOM","text":"Sweden legacy problem , years, individual measurements submitted VDS = 0. biases assessment creates problems statistical models used. Swedish individual measurements (relevant stations) shown year species. zero values 2010 incompatible years. (can found 2007 2008 2010 Swedish Nassarius data, although Nassarius monitored since 2015, show .) Consequently, delete 2010 data. four measurements VDS = 6 2019 2020 strange. well separated bulk data, \\(\\le\\) 2 years. , VDSI submissions stations years suggest four measurements VDS = 6 included index calculations. four large measurements excluded.","code":"wk %>%   filter(     determinand %in% \"VDS\",     country == \"Sweden\"   ) %>%   with(table(value, year, species)) %>%   print(zero.print = \".\") #> , , species = Peringia ulvae #>  #>      year #> value 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 #>     0  257  282    .  310  331  348  350  316  333  317  324  356  359  360 #>     1   59   67   85  128  127  115   87  103   74   97  110   96   87  102 #>     2    9   16   20   19   24   18   21    8   11   11   13    4   12    5 #>     3    1    .    1    3    1    2    2    3    .    2    6    .    .    2 #>     4    7   19    3   15    3    1    1    .    5    2    .    .    .    1 #>     5   29    6    7    9   10    7    7    6    .    1    .    .    .    . #>     6    1    2    7    1    3    2    2    .    .    .    .    3    1    .  biota_data$data <- filter(   biota_data$data,   !(country %in% \"Sweden\" &       determinand %in% c(\"VDS\", \"VDSI\") &       year == 2010   ) ) biota_data$data <- filter(   biota_data$data,   !(country %in% \"Sweden\" &       determinand %in% \"VDS\" &       year %in% c(2019, 2020) &       value == 6   ) )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"denmark---replicates","dir":"Articles","previous_headings":"Biota > Imposex","what":"Denmark - replicates","title":"HELCOM","text":"Denmark reported two results VDSI sub-sample DMU D2 2015 (see ). deleted larger value, suspiciously high Buccinum. looks like sample Neptunea anitqua (see results 2009) although record Neptunea sampled station year 2009.","code":"biota_data$data %>%   filter(     determinand %in% \"VDSI\",     station_name == \"DMU D2\"   ) %>%   select(year, date, station_name, species, sub.sample, replicate, n_individual, value) %>%   arrange(year) #>   year       date station_name          species sub.sample replicate #> 1 2009 11/09/2009       DMU D2 Neptunea antiqua    3948136  60544584 #> 2 2009 11/09/2009       DMU D2 Buccinum undatum    3948135  60544583 #> 3 2011 11/08/2011       DMU D2 Buccinum undatum    3936822  60503664 #> 4 2015 23/08/2015       DMU D2 Buccinum undatum    3725887  45634490 #> 5 2015 23/08/2015       DMU D2 Buccinum undatum    3725887  45634489 #>   n_individual value #> 1           27  3.42 #> 2           51  0.14 #> 3           48  0.02 #> 4           20  2.50 #> 5           20  0.00  biota_data$data <- filter(   biota_data$data,   !(station_name == \"DMU D2\" &       year == 2015 &       determinand %in% \"VDSI\" &       value > 2   ) )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"prepare-data-for-next-stage","dir":"Articles","previous_headings":"","what":"Prepare data for next stage","title":"HELCOM","text":"gets correct variable streamlines data files.","code":"biota_data <- ctsm_tidy_data(biota_data) #>  #> Oddities will be written to 'oddities/biota' with previous oddities backed up to #>  'oddities/biota_backup' #>  #> Cleaning station dictionary #>    Duplicate stations - first one selected: see duplicate_stations.csv #>  #> Cleaning contaminant and biological effects data #>    Submitted.station unrecognised by dictionary: see stations_unrecognised.csv #>    Dropping data with no stations #>    Conflicting QA information - first one selected: see conflicting_QA.csv sediment_data <- ctsm_tidy_data(sediment_data) #>  #> Oddities will be written to 'oddities/sediment' with previous oddities backed up to #>  'oddities/sediment_backup' #>  #> Cleaning station dictionary #>    Duplicate stations - first one selected: see duplicate_stations.csv #>  #> Cleaning contaminant and biological effects data #>    Submitted.station unrecognised by dictionary: see stations_unrecognised.csv #>    Dropping data with no stations water_data <- ctsm_tidy_data(water_data) #>  #> Oddities will be written to 'oddities/water' with previous oddities backed up to #>  'oddities/water_backup' #>  #> Cleaning station dictionary #>    Duplicate stations - first one selected: see duplicate_stations.csv #>  #> Cleaning contaminant and biological effects data #>    Dropping data with no stations"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"biota-1","dir":"Articles","previous_headings":"","what":"Biota","title":"HELCOM","text":"Ad-hoc change merge MU MU&EP data organics Finnish perch need years including 2013 MU&EP measurements, risk mixing MU MU&EP data. Ad-hoc change merge methods analysis Poland PYR10H Ad-hoc change info_TEQ make appropriate human health QS Resolve Finnish perch changes Resolve Polish metoa changes","code":"biota_data$data <- left_join(   biota_data$data,   biota_data$stations[c(\"station_code\", \"country\")],   by = \"station_code\" )  biota_data$data <- mutate(   biota_data$data,   .id = country == \"Finland\" &     species == \"Perca fluviatilis\" &     year <= 2013 &      !(determinand %in% c(\"CD\", \"HG\", \"PB\", \"PFOS\")),   matrix = if_else(     .id & !(determinand %in% c(\"DRYWT%\", \"FATWT%\")),     \"MU&EP\",     matrix   ) )  wk <- biota_data$data %>%   filter(.id & determinand %in% c(\"DRYWT%\", \"FATWT%\")) %>%   mutate(     replicate = max(biota_data$data$replicate) + 1:n(),     matrix = \"MU&EP\",     .id = NULL   )  biota_data$data <- mutate(biota_data$data, .id = NULL)  biota_data$data <- bind_rows(biota_data$data, wk) biota_data$data <- mutate(   biota_data$data,   method_analysis = if_else(     alabo %in% \"IMWP\" &       determinand %in% \"PYR1OH\" &       year %in% 2020:2021,     \"HPLC-FD\",     method_analysis   ) ) info_TEQ[\"CDFO\"] <- 0.0003  biota_data$data$country <- NULL  biota_timeSeries <- ctsm_create_timeSeries(   biota_data,   determinands.control = list(     PFOS = list(det = c(\"N-PFOS\", \"BR-PFOS\"), action = \"sum\"),     SBDE6 = list(       det = c(\"BDE28\", \"BDE47\", \"BDE99\", \"BD100\", \"BD153\", \"BD154\"),        action = \"sum\"     ),     HBCD = list(det = c(\"HBCDA\", \"HBCDB\", \"HBCDG\"), action = \"sum\"),     CB138 = list(det = \"CB138+163\", action = \"replace\"),     SCB6 = list(       det = c(\"CB28\", \"CB52\", \"CB101\", \"CB138\", \"CB153\", \"CB180\"),        action = \"sum\"     ),     TEQDFP = list(det = names(info_TEQ), action = \"bespoke\"),     VDS = list(det = \"VDSI\", action = \"bespoke\"),      INTS = list(det = \"INTSI\", action = \"bespoke\"),     \"LIPIDWT%\" = list(det = c(\"EXLIP%\", \"FATWT%\"), action = \"bespoke\")   ),   normalise = ctsm_normalise_biota_HELCOM,   normalise.control = list(     lipid = list(method = \"simple\", value = 5),      other = list(method = \"none\")    ) ) #>  #> Oddities will be written to 'oddities/biota' with previous oddities backed up to #>  'oddities/biota_backup' #>  #> Cleaning data #>    Stations in data not in station dictionary: deleted data in 'unidentified_stations.csv #>    Dropping stations with no data between 2016 and 2021  #>    Dropping samples with only auxiliary variables #>    Unexpected or missing values for 'sex': see sex_queries.csv #>    Unexpected or missing values for 'matrix': see matrix_queries.csv #>    Unexpected or missing values for 'basis': see basis_queries.csv #>    imposex index units changed from 'idx' to 'st' before merging with individual data #>    Bile metabolite units changed from 'ng/g' to 'ng/ml' and from 'ug/kg' to 'ug/l' #> Warning in get.info.imposex(species, determinand, info$imposex, \"min_value\", : #> Species determinand combinations not recognised: Tritia nitida (reticulata) #> INTS, Buccinum undatum INTS, Buccinum undatum IMPS, Neptunea antiqua IMPS, #> Neptunea antiqua INTS #> Warning in get.info.imposex(species, determinand, info$imposex, \"max_value\", : #> Species determinand combinations not recognised: Tritia nitida (reticulata) #> INTS, Buccinum undatum INTS, Buccinum undatum IMPS, Neptunea antiqua IMPS, #> Neptunea antiqua INTS #>    Unexpected or missing values for 'value': see value_queries.csv #>    Replicate measurements, only first retained: see replicate_measurements.csv #>    Non-positive detection limits: see non_positive_det_limits.csv #>    Non-positive quantification limits: see non_positive_quant_limits.csv #>    Limit of quantification less than limit of detection: see limits_inconsistent.csv #>    Censoring codes D and Q inconsistent with respective limits: see censoring_codes_inconsistent.csv #>    Detection limit higher than data: see detection_limit_high.csv #>    Non-positive uncertainties: see non_positive_uncertainties.csv #>    Large uncertainties: see large_uncertainties.csv #>    Data submitted as N-PFOS, BR-PFOS summed to give PFOS #>    Data submitted as BDE28, BDE47, BDE99, BD100, BD153, BD154 summed to give  #> SBDE6 #>      1624 of 3119 samples lost due to incomplete submissions #>    Data submitted as HBCDA, HBCDB, HBCDG summed to give HBCD #>      7 of 153 samples lost due to incomplete submissions #>    Data submitted as CB138+163 relabelled as CB138  #>    Data submitted as CB28, CB52, CB101, CB138, CB153, CB180 summed to give SCB6 #>      228 of 5190 samples lost due to incomplete submissions #>    Data submitted as  #> CB77, CB81, CB105, CB118, CB126, CB156, CB157, CB167, CB169, CDD1N, CDD4X, CDD6P, CDD6X, CDD9X, CDDO, CDF2N, CDF2T, CDF4X, CDF6P, CDF6X, CDF9P, CDF9X, CDFO, CDFP2, CDFX1, TCDD  #> summed to give TEQDFP #>      4989 of 5517 samples lost due to incomplete submissions #>    inconsistent VDS and VDSI submitted in same year: see determinand_link_VDS.csv #>    Data submitted as VDSIrelabelled as VDS #>    Data submitted as EXLIP% or FATWT% relabelled as LIPIDWT%  #>  #> Creating time series data #>    Converting data to appropriate basis for statistical analysis #>    Losing 595 out of 40828 records in basis conversion due to missing, censored #>    or zero drywt or lipidwt values. #>    Dropping bivalve and gastropod contaminant data collected during the #>     spawning season, which is taken to be the following months: #>     April, May, June, July #>    Normalising lipid to 5% #>    No normalisation for other #>    Dropping groups of compounds / stations with no data between 2016 and 2021 biota_timeSeries$data <- mutate(   biota_timeSeries$data,    matrix = if_else(     year <= 2013 & matrix == \"MU&EP\",      \"MU\",      matrix   ) ) biota_timeSeries$data <- left_join(   biota_timeSeries$data,    biota_data$stations[c(\"station_code\", \"country\")],   by = \"station_code\" )  biota_timeSeries$data <- mutate(   biota_timeSeries$data,    method_analysis = if_else(     country == \"Poland\" &         determinand %in% \"PYR1OH\" &       year %in% 2020,     \"HPLC-ESI-MS-MS\",      method_analysis   ),    method_analysis = if_else(     country == \"Poland\" &         determinand %in% \"PYR1OH\" &       year %in% 2021,     \"GC-MS-MS\",      method_analysis   ), )  biota_timeSeries$data$country <- NULL"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"sediment-1","dir":"Articles","previous_headings":"","what":"Sediment","title":"HELCOM","text":"","code":"sediment_timeSeries <- ctsm_create_timeSeries(   sediment_data,   determinands.control = list(     SBDE6 = list(       det = c(\"BDE28\", \"BDE47\", \"BDE99\", \"BD100\", \"BD153\", \"BD154\"),        action = \"sum\"     ),     HBCD = list(det = c(\"HBCDA\", \"HBCDB\", \"HBCDG\"), action = \"sum\")   ),   normalise = ctsm_normalise_sediment_HELCOM,   normalise.control = list(     metals = list(method = \"pivot\", normaliser = \"AL\"),      copper = list(method = \"hybrid\", normaliser = \"CORG\", value = 5),     organics = list(method = \"simple\", normaliser = \"CORG\", value = 5)    ) ) #>  #> Oddities will be written to 'oddities/sediment' with previous oddities backed up to #>  'oddities/sediment_backup' #>  #> Cleaning data #>    Stations in data not in station dictionary: deleted data in 'unidentified_stations.csv #>    Dropping stations with no data between 2016 and 2021  #>    Dropping samples with only auxiliary variables #>    Relabelling matrix SED62 as SED63 and SED500, SED1000, SED2000 as SEDTOT #>    Unexpected or missing values for 'basis': see basis_queries.csv #>    Unexpected or missing values for 'value': see value_queries.csv #>    Replicate measurements, only first retained: see replicate_measurements.csv #>    Non-positive detection limits: see non_positive_det_limits.csv #>    Non-positive quantification limits: see non_positive_quant_limits.csv #>    Limit of quantification less than limit of detection: see limits_inconsistent.csv #>    Censoring codes D and Q inconsistent with respective limits: see censoring_codes_inconsistent.csv #>    Detection limit higher than data: see detection_limit_high.csv #>    Non-positive uncertainties: see non_positive_uncertainties.csv #>    Large uncertainties: see large_uncertainties.csv #>    Data submitted as BDE28, BDE47, BDE99, BD100, BD153, BD154 summed to give  #> SBDE6 #>      33 of 115 samples lost due to incomplete submissions #>    Data submitted as HBCDA, HBCDB, HBCDG summed to give HBCD #>  #> Creating time series data #>    Converting data to appropriate basis for statistical analysis #>    Normalising copper to CORG using pivot values #>    Removing sediment data where normaliser is a less than #>    Normalising metals to AL using pivot values #>    Normalising organics to 5% CORG #>    Removing sediment data where normaliser is a less than #>    Dropping groups of compounds / stations with no data between 2016 and 2021"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"water","dir":"Articles","previous_headings":"","what":"Water","title":"HELCOM","text":"","code":"water_timeSeries <- ctsm_create_timeSeries(   water_data,   determinands.control = list(     PFOS = list(det = c(\"N-PFOS\", \"BR-PFOS\"), action = \"sum\")   ) ) #>  #> Oddities will be written to 'oddities/water' with previous oddities backed up to #>  'oddities/water_backup' #>  #> Cleaning data #>    Dropping stations with no data between 2016 and 2021 #>    Unexpected or missing values for 'basis': see basis_queries.csv #>    Unexpected or missing values for 'unit': see unit_queries.csv #>    Non-positive detection limits: see non_positive_det_limits.csv #>    Censoring codes D and Q inconsistent with respective limits: see censoring_codes_inconsistent.csv #>    Detection limit higher than data: see detection_limit_high.csv #>  #> Creating time series data #>    Converting data to appropriate basis for statistical analysis #>    Dropping groups of compounds / stations with no data between 2016 and 2021"},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"sediment-2","dir":"Articles","previous_headings":"Assessment","what":"Sediment","title":"HELCOM","text":"Main runs Check convergence","code":"sediment_assessment <- run_assessment(   sediment_timeSeries,   AC = \"EQS\",   parallel = TRUE ) #> Setting up clusters: be patient, it can take a while! check_assessment(sediment_assessment) #> All assessment models have converged"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"biota-2","dir":"Articles","previous_headings":"Assessment","what":"Biota","title":"HELCOM","text":"Main runs Preliminary analysis required imposex assessment. Takes long time run!!!!!","code":""},{"path":"http://osparcomm.github.io/HARSAT/articles/example_HELCOM.html","id":"helcom-imposex-preparation","dir":"Articles","previous_headings":"Assessment","what":"HELCOM imposex preparation","title":"HELCOM","text":"Load libraries Get data See individual data Get cut points country. used terminology MIME code (e.g. regionID = country , whereas regionID ~ country + region MIME). difficulty dealing Neptunea nearly zero gap values (records class 2 3) example: Denmark 28 1 0 0 1 0 0. Construct new variable VDS can combine larger categories observations without changing raw data. Combine larger categories observations Redefine indexID regionID don’t worry multiple species. Split regionID, estimate cut points level indexID. Check convergence Get confidence limits estimated VDSI indexID.","code":"library(\"dplyr\") library(\"tibble\") library(\"tidyr\") library(\"parallel\") library(\"pbapply\") wk_data <- mutate(   biota_timeSeries$data,   .imposex = ctsm_get_info(     biota_timeSeries$info$determinand,      .data$determinand,      \"group\",      \"biota\",      sep = \"_\"   ) )  wk_data <- filter(wk_data, .imposex %in% \"Imposex\")  wk_data <- wk_data[c(   \"seriesID\", \"station_code\", \"year\", \"species\", \"determinand\",    \"concentration\", \"n_individual\", \"%FEMALEPOP\" )]  wk_data <- left_join(   wk_data,    biota_timeSeries$stations[c(\"station_code\", \"country\", \"HELCOM_subbasin\")],   by = \"station_code\" ) stopifnot(is.integer(wk_data$n_individual)) wk_data <- wk_data %>%   group_by(station_code, determinand, species, year) %>%    filter(all(n_individual == 1L)) %>%    ungroup() %>%    droplevels() %>%    select(-n_individual) wk_data <- unite(wk_data, \"regionID\", country, sep = \" \", remove = FALSE) with(wk_data, table(regionID, concentration, species)) #> , , species = Buccinum undatum #>  #>          concentration #> regionID     0    1    2    3    4    5    6 #>   Denmark  815   35    2    3    4    0    0 #>   Sweden     0    0    0    0    0    0    0 #>  #> , , species = Littorina littorea #>  #>          concentration #> regionID     0    1    2    3    4    5    6 #>   Denmark  227   75    8   69    0    0    0 #>   Sweden     0    0    0    0    0    0    0 #>  #> , , species = Neptunea antiqua #>  #>          concentration #> regionID     0    1    2    3    4    5    6 #>   Denmark   28    1    0    0    1    0    0 #>   Sweden     0    0    0    0    0    0    0 #>  #> , , species = Peringia ulvae #>  #>          concentration #> regionID     0    1    2    3    4    5    6 #>   Denmark    0    0    0    0    0    0    0 #>   Sweden  4243 1252  171   22   54   75   11 #>  #> , , species = Tritia nitida (reticulata) #>  #>          concentration #> regionID     0    1    2    3    4    5    6 #>   Denmark   37   55   13   47   54    0    0 #>   Sweden     0    0    0    0    0    0    0  wk_data <- wk_data %>%    filter(!.data$species %in% \"Neptunea antiqua\") %>%    select(-determinand, -\"%FEMALEPOP\") %>%   droplevels()  wk_data %>% mutate(across(where(is.character), factor)) %>% summary() #>                        seriesID     station_code       year      #>  5972 VDS Peringia ulvae SB: 519   5972   : 519   Min.   :2007   #>  6253 VDS Peringia ulvae SB: 457   6253   : 457   1st Qu.:2011   #>  5846 VDS Peringia ulvae SB: 445   5846   : 445   Median :2014   #>  6020 VDS Peringia ulvae SB: 423   6020   : 423   Mean   :2015   #>  6241 VDS Peringia ulvae SB: 404   6241   : 404   3rd Qu.:2018   #>  6098 VDS Peringia ulvae SB: 387   6098   : 387   Max.   :2021   #>  (Other)                   :4637   (Other):4637                  #>                        species     concentration       regionID    #>  Buccinum undatum          : 859   Min.   :0.0000   Denmark:1444   #>  Littorina littorea        : 379   1st Qu.:0.0000   Sweden :5828   #>  Peringia ulvae            :5828   Median :0.0000                  #>  Tritia nitida (reticulata): 206   Mean   :0.4286                  #>                                    3rd Qu.:1.0000                  #>                                    Max.   :6.0000                  #>                                                                    #>     country                   HELCOM_subbasin #>  Denmark:1444   Arkona Basin          : 394   #>  Sweden :5828   Bornholm Basin        :1222   #>                 Great Belt            : 474   #>                 Kattegat              : 877   #>                 Northern Baltic Proper:1289   #>                 The Sound             : 666   #>                 Western Gotland Basin :2350 wk_data <- mutate(wk_data, VDS = .data$concentration)  with(wk_data, table(regionID, VDS, species)) #> , , species = Buccinum undatum #>  #>          VDS #> regionID     0    1    2    3    4    5    6 #>   Denmark  815   35    2    3    4    0    0 #>   Sweden     0    0    0    0    0    0    0 #>  #> , , species = Littorina littorea #>  #>          VDS #> regionID     0    1    2    3    4    5    6 #>   Denmark  227   75    8   69    0    0    0 #>   Sweden     0    0    0    0    0    0    0 #>  #> , , species = Peringia ulvae #>  #>          VDS #> regionID     0    1    2    3    4    5    6 #>   Denmark    0    0    0    0    0    0    0 #>   Sweden  4243 1252  171   22   54   75   11 #>  #> , , species = Tritia nitida (reticulata) #>  #>          VDS #> regionID     0    1    2    3    4    5    6 #>   Denmark   37   55   13   47   54    0    0 #>   Sweden     0    0    0    0    0    0    0 wk_data <- within(wk_data, {      id <- species == \"Buccinum undatum\"   VDS[id & VDS >= 2] <- 2    })  with(wk_data, table(regionID, VDS, species)) #> , , species = Buccinum undatum #>  #>          VDS #> regionID     0    1    2    3    4    5    6 #>   Denmark  815   35    9    0    0    0    0 #>   Sweden     0    0    0    0    0    0    0 #>  #> , , species = Littorina littorea #>  #>          VDS #> regionID     0    1    2    3    4    5    6 #>   Denmark  227   75    8   69    0    0    0 #>   Sweden     0    0    0    0    0    0    0 #>  #> , , species = Peringia ulvae #>  #>          VDS #> regionID     0    1    2    3    4    5    6 #>   Denmark    0    0    0    0    0    0    0 #>   Sweden  4243 1252  171   22   54   75   11 #>  #> , , species = Tritia nitida (reticulata) #>  #>          VDS #> regionID     0    1    2    3    4    5    6 #>   Denmark   37   55   13   47   54    0    0 #>   Sweden     0    0    0    0    0    0    0 wk_data <- wk_data %>%    unite(\"indexID\", station_code, year, species, sep = \" \", remove = FALSE) %>%    unite(\"regionID\", regionID, species, sep = \" \", remove = FALSE) %>%    mutate(indexID = factor(indexID)) %>%    as.data.frame()  with(wk_data, table(regionID, VDS)) #>                                     VDS #> regionID                                0    1    2    3    4    5    6 #>   Denmark Buccinum undatum            815   35    9    0    0    0    0 #>   Denmark Littorina littorea          227   75    8   69    0    0    0 #>   Denmark Tritia nitida (reticulata)   37   55   13   47   54    0    0 #>   Sweden Peringia ulvae              4243 1252  171   22   54   75   11 wk_split <- split(wk_data, wk_data$regionID)  wk.cores <- detectCores() wk.cluster <- makeCluster(wk.cores - 1, outfile = \"\")  clusterExport(wk.cluster, c(\"wk_split\")) clusterExport(wk.cluster, ctsm.VDS.varlist, envir = cstm.VDS.environment())  # clusterEvalQ(wk.cluster, { #   library(\"MASS\") # })  biota.VDS.estimates <- pblapply(   wk_split,    ctsm.VDS.index.opt,    calc.vcov = TRUE,    cl = wk.cluster )  stopCluster(wk.cluster) all(sapply(biota.VDS.estimates, \"[[\", \"convergence\") == 0) #> [1] TRUE  # saveRDS( #   biota.VDS.estimates, #   file.path(\"RData\", \"VDS estimates.rds\") # ) set.seed(230504)  biota.VDS.cl <- lapply(biota.VDS.estimates, ctsm.VDS.cl) biota.VDS.cl <- do.call(rbind, biota.VDS.cl)  row.names(biota.VDS.cl) <- do.call(   paste,    biota.VDS.cl[c(\"station_code\", \"year\", \"species\")] )  biota.VDS.cl %>% mutate(across(where(is.character), factor)) %>% summary() #>      lower              upper                              species    #>  Min.   :0.003795   Min.   :0.1038   Buccinum undatum          : 26   #>  1st Qu.:0.053665   1st Qu.:0.3215   Littorina littorea        : 17   #>  Median :0.147798   Median :0.5178   Peringia ulvae            :196   #>  Mean   :0.315700   Mean   :0.7408   Tritia nitida (reticulata): 10   #>  3rd Qu.:0.423762   3rd Qu.:0.9429                                    #>  Max.   :3.529276   Max.   :3.9709                                    #>                                                                       #>       year       station_code #>  Min.   :2007   5799   : 13   #>  1st Qu.:2011   5846   : 13   #>  Median :2015   5972   : 13   #>  Mean   :2015   6020   : 13   #>  3rd Qu.:2018   6086   : 13   #>  Max.   :2021   6098   : 13   #>                 (Other):171  # saveRDS( #   biota.VDS.cl, #   file.path(\"RData\", \"VDS confidence limits.rds\") # )  rm(wk_data, wk_split, wk.cluster, wk.cores)"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_external_data.html","id":"read-data","dir":"Articles","previous_headings":"","what":"Read data","title":"External data","text":"Mercury data supporting variables station dictionary","code":"biota_data <- read_data(   compartment = \"biota\",   purpose = \"AMAP\",   contaminants = \"AMAP_external_data_new_data_only_CAN_MarineMammals.csv\",   stations = \"AMAP_external_new_stations_only.csv\",   data_dir = file.path(working.directory, \"data\", \"example_external_data\"),   data_format = \"external\",   info_dir = file.path(working.directory, \"information\"),   control = list(region_id = \"AMAP_region\") ) #> Reading station dictionary from: #>  '/Users/stuart/git/HARSAT/data/example_external_data/AMAP_external_new_stations_only.csv' #>  #> Reading contaminant and biological effects data from: #>  '/Users/stuart/git/HARSAT/data/example_external_data/AMAP_external_data_new_data_only_CAN_MarineMammals.csv' #>  #> Argument max_year taken to be the maximum year in the data: 2017"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_external_data.html","id":"prepare-data-for-next-stage","dir":"Articles","previous_headings":"","what":"Prepare data for next stage","title":"External data","text":"Get correct variables streamline data files","code":"biota_data <- ctsm_tidy_data(biota_data) #>  #> Oddities will be written to 'oddities/biota' with previous oddities backed up to #>  'oddities/biota_backup' #>  #> Cleaning station dictionary #>  #> Cleaning contaminant and biological effects data"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_external_data.html","id":"construct-timeseries","dir":"Articles","previous_headings":"","what":"Construct timeseries","title":"External data","text":"Uses OSPAR basis choice mercury","code":"biota_timeSeries <- ctsm_create_timeSeries(   biota_data,   get_basis = get_basis_biota_OSPAR ) #>  #> Oddities will be written to 'oddities/biota' with previous oddities backed up to #>  'oddities/biota_backup' #>  #> Cleaning data #>    Dropping stations with no data between 2012 and 2017 #>    Unexpected or missing values for 'basis': see basis_queries.csv #>    Unexpected or missing values for 'value': see value_queries.csv #>  #> Creating time series data #>    Converting data to appropriate basis for statistical analysis #>    Losing 25 out of 4629 records in basis conversion due to missing, censored #>    or zero drywt or lipidwt values. #>    Dropping groups of compounds / stations with no data between 2012 and 2017"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_external_data.html","id":"assessment","dir":"Articles","previous_headings":"","what":"Assessment","title":"External data","text":"Main runs Use code takes long time run","code":"biota_assessment <- run_assessment(   biota_timeSeries,    AC = c(\"NRC\", \"LRC\", \"MRC\", \"HRC\") ) #>  #> assessing series:  station_code A1; determinand HG; species Phoca hispida; matrix LI; subseries adult; basis W; unit ug/kg #> Loading required package: Matrix #>  #> Attaching package: 'Matrix' #> The following objects are masked from 'package:tidyr': #>  #>     expand, pack, unpack #> Loading required package: nlme #>  #> Attaching package: 'nlme' #> The following object is masked from 'package:lme4': #>  #>     lmList #> The following object is masked from 'package:dplyr': #>  #>     collapse #> This is mgcv 1.8-42. For overview type 'help(\"mgcv-package\")'. #>  #> Attaching package: 'optimx' #> The following object is masked from 'package:nlme': #>  #>     coef<- #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code A1; determinand HG; species Phoca hispida; matrix LI; subseries juvenile; basis W; unit ug/kg #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code A1; determinand HG; species Phoca hispida; matrix MU; subseries adult; basis W; unit ug/kg  #>  #> assessing series:  station_code A1; determinand HG; species Phoca hispida; matrix MU; subseries juvenile; basis W; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code A20; determinand HG; species Phoca hispida; matrix LI; subseries adult; basis W; unit ug/kg  #>  #> assessing series:  station_code A20; determinand HG; species Phoca hispida; matrix LI; subseries juvenile; basis W; unit ug/kg  #>  #> assessing series:  station_code A20; determinand HG; species Phoca hispida; matrix MU; subseries adult; basis W; unit ug/kg  #>  #> assessing series:  station_code A20; determinand HG; species Phoca hispida; matrix MU; subseries juvenile; basis W; unit ug/kg  #>  #> assessing series:  station_code A3; determinand HG; species Delphinapterus leucas; matrix LI; subseries large; basis W; unit ug/kg  #>  #> assessing series:  station_code A3; determinand HG; species Delphinapterus leucas; matrix LI; subseries small; basis W; unit ug/kg  #>  #> assessing series:  station_code A3; determinand HG; species Delphinapterus leucas; matrix MU; subseries large; basis W; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code A3; determinand HG; species Delphinapterus leucas; matrix MU; subseries small; basis W; unit ug/kg  #>  #> assessing series:  station_code A3; determinand HG; species Ursus maritimus; matrix LI; subseries adult_female; basis W; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code A3; determinand HG; species Ursus maritimus; matrix LI; subseries adult_male; basis W; unit ug/kg  #>  #> assessing series:  station_code A3; determinand HG; species Ursus maritimus; matrix LI; subseries juvenile; basis W; unit ug/kg #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code A6; determinand HG; species Phoca hispida; matrix LI; subseries adult; basis W; unit ug/kg  #>  #> assessing series:  station_code A6; determinand HG; species Phoca hispida; matrix LI; subseries juvenile; basis W; unit ug/kg  #>  #> assessing series:  station_code A6; determinand HG; species Phoca hispida; matrix MU; subseries adult; basis W; unit ug/kg  #>  #> assessing series:  station_code A6; determinand HG; species Phoca hispida; matrix MU; subseries juvenile; basis W; unit ug/kg  #>  #> assessing series:  station_code A6; determinand HG; species Ursus maritimus; matrix LI; subseries adult_female; basis W; unit ug/kg  #>  #> assessing series:  station_code A6; determinand HG; species Ursus maritimus; matrix LI; subseries adult_male; basis W; unit ug/kg  #>  #> assessing series:  station_code A6; determinand HG; species Ursus maritimus; matrix LI; subseries juvenile; basis W; unit ug/kg  #>  #> assessing series:  station_code A8; determinand HG; species Phoca hispida; matrix LI; subseries adult; basis W; unit ug/kg  #>  #> assessing series:  station_code A8; determinand HG; species Phoca hispida; matrix LI; subseries juvenile; basis W; unit ug/kg  #>  #> assessing series:  station_code A8; determinand HG; species Phoca hispida; matrix MU; subseries adult; basis W; unit ug/kg #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code A8; determinand HG; species Phoca hispida; matrix MU; subseries juvenile; basis W; unit ug/kg  #>  #> assessing series:  station_code A9; determinand HG; species Delphinapterus leucas; matrix EP; subseries large; basis W; unit ug/kg  #>  #> assessing series:  station_code A9; determinand HG; species Delphinapterus leucas; matrix EP; subseries small; basis W; unit ug/kg #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code A9; determinand HG; species Delphinapterus leucas; matrix KI; subseries large; basis W; unit ug/kg  #>  #> assessing series:  station_code A9; determinand HG; species Delphinapterus leucas; matrix KI; subseries small; basis W; unit ug/kg  #>  #> assessing series:  station_code A9; determinand HG; species Delphinapterus leucas; matrix LI; subseries large; basis W; unit ug/kg  #>  #> assessing series:  station_code A9; determinand HG; species Delphinapterus leucas; matrix LI; subseries small; basis W; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code A9; determinand HG; species Delphinapterus leucas; matrix MU; subseries large; basis W; unit ug/kg  #>  #> assessing series:  station_code A9; determinand HG; species Delphinapterus leucas; matrix MU; subseries small; basis W; unit ug/kg biota_assessment <- run_assessment(   biota_timeSeries,   AC = c(\"NRC\", \"LRC\", \"MRC\", \"HRC\")   parallel = TRUE )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_external_data.html","id":"check-convergence","dir":"Articles","previous_headings":"Assessment","what":"Check convergence","title":"External data","text":"","code":"check_assessment(biota_assessment) #> All assessment models have converged"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_external_data.html","id":"summary-files","dir":"Articles","previous_headings":"","what":"Summary files","title":"External data","text":"writes summary data file output/example_external_data.","code":"summary.dir <- file.path(working.directory, \"output\", \"example_external_data\")  if (!dir.exists(summary.dir)) {   dir.create(summary.dir, recursive = TRUE) }   write_summary_table(   biota_assessment,   output_dir = summary.dir,     classColour = list(     below = c(\"NRC\" = \"blue\", \"LRC\" = \"green\", \"MRC\" = \"orange\", \"HRC\" = \"darkorange\"),     above = c(\"NRC\" = \"red\", \"LRC\" = \"red\", \"MRC\" = \"red\", \"HRC\" = \"red\"),     none = \"black\"   ) )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_external_data.html","id":"graphics-output","dir":"Articles","previous_headings":"","what":"Graphics output","title":"External data","text":"Plots assessment either data (file_type = “data”) annual index (file_type = “index”) (default) Outputs can png pdf Can subset assessment based variables either timeSeries stations components object: commonly determinand, matrix, species, station_code station_name; can also use series identifier row.names(timeSeries) subset NULL (default), timeseries plotted (can take time) Graphics plots written files output/graphics.","code":"graphics.dir <- file.path(working.directory, \"output\", \"graphics\")  if (!dir.exists(graphics.dir)) {   dir.create(graphics.dir, recursive = TRUE) }   plot_assessment(   biota_assessment,   subset = species %in% \"Phoca hispida\",   output_dir = graphics.dir,    file_type = \"data\",   file_format = \"png\" ) plot_assessment(   biota_assessment,   subset = matrix %in% \"LI\",   output_dir = graphics.dir,    file_type = \"index\",   file_format = \"pdf\" ) plot_assessment(   biota_assessment,   subset = station_code %in% \"A1\",   output_dir = graphics.dir,    file_type = \"data\",   file_format = \"pdf\" ) plot_assessment(   biota_assessment,    subset = series == \"A1 HG Phoca hispida LI adult\",   output_dir = graphics.dir,    file_format = \"pdf\" )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_simple_OSPAR.html","id":"read-data-from-ices-extraction","dir":"Articles","previous_headings":"","what":"Read data from ICES extraction","title":"Simple OSPAR","text":"three input data sets: - contaminant data - station dictionary - quality assurance data (accurately called chemical methods file); note disappear first release harsat package Load R package , use working directory find data files. use data files, need point directory containing copy.","code":"library(here) working.directory <- here() biota_data <- read_data(   compartment = \"biota\",    purpose = \"OSPAR\",                                  contaminants = \"test_data.csv\",    stations = \"station_dictionary.csv\",    QA = \"quality_assurance.csv\",   data_dir = file.path(working.directory, \"data\", \"example_simple_OSPAR\"),   data_format = \"ICES_old\",   info_files = list(     determinand = \"determinand_simple_OSPAR.csv\",      thresholds = \"thresholds_biota_simple_OSPAR.csv\"   ),   info_dir = file.path(working.directory, \"information\"),    extraction = \"2022/01/11\",   max_year = 2020L   ) #> Reading station dictionary from: #>  '/Users/stuart/git/HARSAT/data/example_simple_OSPAR/station_dictionary.csv' #>  #> Reading contaminant and biological effects data from: #>  '/Users/stuart/git/HARSAT/data/example_simple_OSPAR/test_data.csv' #>  #> Reading QA data from '/Users/stuart/git/HARSAT/data/example_simple_OSPAR/quality_assurance.csv'"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_simple_OSPAR.html","id":"prepare-data-for-next-stage","dir":"Articles","previous_headings":"Read data from ICES extraction","what":"Prepare data for next stage","title":"Simple OSPAR","text":"Gets correct variable streamlines data files","code":"biota_data <- ctsm_tidy_data(biota_data) #>  #> Oddities will be written to 'oddities/biota' with previous oddities backed up to #>  'oddities/biota_backup' #>  #> Cleaning station dictionary #>    Duplicate stations - first one selected: see duplicate_stations.csv #>  #> Cleaning contaminant and biological effects data #>    Submitted.station unrecognised by dictionary: see stations_unrecognised.csv #>    Dropping data with no stations"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_simple_OSPAR.html","id":"construct-timeseries","dir":"Articles","previous_headings":"Read data from ICES extraction","what":"Construct timeseries","title":"Simple OSPAR","text":"Identifies groups data form coherent timeseries. Also lot data cleaning processing (creates oddities folder). Identical (apart call) :","code":"biota_timeSeries <- ctsm_create_timeSeries(   biota_data,   determinands = c(\"CD\", \"CB153\", \"HBCD\",\"HBCDA\", \"HBCDG\", \"PYR1OH\"),    determinands.control = list(     HBCD = list(det = c(\"HBCDA\", \"HBCDB\", \"HBCDG\"), action = \"sum\"),     \"LIPIDWT%\" = list(det = c(\"EXLIP%\", \"FATWT%\"), action = \"bespoke\")   ),    get_basis = get_basis_biota_OSPAR ) #>  #> Oddities will be written to 'oddities/biota' with previous oddities backed up to #>  'oddities/biota_backup' #>  #> Cleaning data #>    Dropping stations with no data between 2015 and 2020  #>    Dropping samples with only auxiliary variables #>    Unexpected or missing values for 'matrix': see matrix_queries.csv #>    Unexpected or missing values for 'basis': see basis_queries.csv #>    Bile metabolite units changed from 'ng/g' to 'ng/ml' and from 'ug/kg' to 'ug/l' #>    Replicate measurements, only first retained: see replicate_measurements.csv #>    Limit of quantification less than limit of detection: see limits_inconsistent.csv #>    Detection limit higher than data: see detection_limit_high.csv #>    Data submitted as HBCDA, HBCDB, HBCDG summed to give HBCD #>    Data submitted as EXLIP% or FATWT% relabelled as LIPIDWT%  #>  #> Creating time series data #>    Converting data to appropriate basis for statistical analysis #>    Losing 32 out of 392 records in basis conversion due to missing, censored #>    or zero drywt or lipidwt values. #>    Dropping bivalve and gastropod contaminant data collected during the #>     spawning season, which is taken to be the following months: #>     April, May, June, July  #>    Dropping groups of compounds / stations with no data between 2015 and 2020 ctsm_create_timeSeries(   biota_data,   determinands = ctsm_get_determinands(\"biota\"),   determinands.control = list(     HBCD = list(det = c(\"HBCDA\", \"HBCDB\", \"HBCDG\"), action = \"sum\"),     \"LIPIDWT%\" = list(det = c(\"EXLIP%\", \"FATWT%\"), action = \"bespoke\")   ) )  ctsm_create_timeSeries(   biota_data,   determinands.control = list(     HBCD = list(det = c(\"HBCDA\", \"HBCDB\", \"HBCDG\"), action = \"sum\"),     \"LIPIDWT%\" = list(det = c(\"EXLIP%\", \"FATWT%\"), action = \"bespoke\")   ) )"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_simple_OSPAR.html","id":"assessment","dir":"Articles","previous_headings":"","what":"Assessment","title":"Simple OSPAR","text":"statistical analysis Check convergence - errors time","code":"biota_assessment <- run_assessment(   biota_timeSeries,    AC = c(\"BAC\", \"EAC\", \"EQS\", \"HQS\") ) #>  #> assessing series:  station_code 11461; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 11461; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 12156; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 12164; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 12164; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1235; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1235; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 1235; determinand HBCD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1235; determinand HBCDA; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1235; determinand HBCDG; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 13059; determinand CB153; species Spisula solida; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 13059; determinand CD; species Spisula solida; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 1345; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1345; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 1345; determinand HBCD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1345; determinand HBCDA; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1345; determinand HBCDG; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand HBCD; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand HBCDA; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand HBCDG; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1388; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1388; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 2717; determinand PYR1OH; species Limanda limanda; matrix BI; method_analysis HPLC-FD; unit ng/ml  #>  #> assessing series:  station_code 3282; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3282; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3433; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3433; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3441; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3441; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 7132; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 7132; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg check_assessment(biota_assessment) #> All assessment models have converged"},{"path":"http://osparcomm.github.io/HARSAT/articles/example_simple_OSPAR.html","id":"summary-files","dir":"Articles","previous_headings":"","what":"Summary files","title":"Simple OSPAR","text":"","code":"summary.dir <- file.path(working.directory, \"output\", \"example_simple_OSPAR\")  if (!dir.exists(summary.dir)) {   dir.create(summary.dir, recursive = TRUE) }  webGroups <- list(   levels = c(\"Metals\", \"Metabolites\", \"Organobromines\", \"Chlorobiphenyls\"),     labels = c(     \"Metals\", \"PAH metabolites\", \"Organobromines\",  \"Polychlorinated biphenyls\"   ) )  classColour <- list(   below = c(     \"BAC\" = \"blue\",      \"EAC\" = \"green\",      \"EQS\" = \"green\",     \"HQS\" = \"green\"   ),   above = c(     \"BAC\" = \"orange\",      \"EAC\" = \"red\",      \"EQS\" = \"red\",     \"HQS\" = \"red\"   ),    none = \"black\" )  write_summary_table(   biota_assessment,    determinandGroups = webGroups,   classColour = classColour,   collapse_AC = list(EAC = c(\"EAC\", \"EQS\")),   output_dir = summary.dir,  )"},{"path":[]},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/articles/file-management.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"File management","text":"R package harsat designed make easy work files. harsat uses following different kinds file: Data files. stored data directory anywhere file system. actual data (contaminant measurments station dictionary) files. TAB files downloaded ICES webservice (.e. ICES format) CSV files put together (simpler external format). Analysis files. drive actual analysis. Three files particulary important: determinand file, species file (biota assessment) threshold file. normally keep analysis directory somewhere file system. CSV files, smaller won’t change anywhere near often data files. Configuration files. several additional configuration files provide information , example, chemical methods pivot values sediment normalisation. harsat package provides default versions files fine assessments. However, may override defaults putting modified copies files analysis directory described . configuration files also CSV files. Datasets page provides zip files : data assessment files vignette analysis files recent OSPAR, HELCOM AMAP assessments default additional configuration files need assemble reliable set files assessment, data directory analysis directory. support full reproducibility, good practice also put copy configuration files (whether modified ) analysis directory. updates R harsat package may change contents default configuration files. data files analysis files, copied modified configuration files put analysis directory, affected.","code":""},{"path":"http://osparcomm.github.io/HARSAT/articles/file-management.html","id":"typical-workflow","dir":"Articles","previous_headings":"","what":"Typical workflow","title":"File management","text":"Let’s imagine want run analysis harsat, already installed R package (described Getting started page). Now need data. Typically get ICES webservice, put together data files using simpler external format. now let’s imagine want try OSPAR vignette. can navigate Datasets page, look approprate zip file download OSPAR vignette. download unzip file (can unzip anywhere like, let’s pretend ’re using Windows unzip : C:\\Users\\stuart\\OSPAR_vignette) ’ll see disk contains files follows: means directories follows: Data directory: C:\\Users\\stuart\\OSPAR_vignette\\data Analysis directory: C:\\Users\\stuart\\OSPAR_vignette\\analysis Obviously, can put directories anywhere like file system. can even put removable disk like, network shared drive. can also call directories something else. example, might call data_vignette analysis_vignette distinguish assessments. , now let’s see might use run analysis.","code":"+ C:\\Users\\stuart\\OSPAR_vignette   |   + data   | |   | + test_data.csv   | + station_dictionary.csv   | + quality_assurance.csv   |   + analysis      |     + determinand.csv     + species.csv     + thresholds_biota.csv"},{"path":"http://osparcomm.github.io/HARSAT/articles/file-management.html","id":"reading-your-data-files","dir":"Articles","previous_headings":"","what":"Reading your data files","title":"File management","text":"Virtually work need involves call harsat’s read_data() function. Let’s suppose R working directory (R Project) C:\\Users\\stuart\\OSPAR_vignette\\. call typically look like : default, function looks data analysis files directories called data assessment nested inside working directory. called something else, can use data_dir analysis_dir arguments. example: can also specify absolute path names important things see : Note use file.path() make portable pathnames. course, user can use whatever filename pattern works best . info_path parameter can vector well single string. harsat actually search every directory vector, looking files like determinand.csv. file found local analysis directory, gets read used. , may try directories vector. get end ’ve still found particular file (especially common standard ones like matrix.csv translates common codes) harsat’s built-directory configuration files gets used last resort. file really essential still can’t find , harsat immediately throw error can intervene. harsat , log file actually used, also log “thumbprint” file contents – typically something like string hexadecimal digits. whereever file comes , long contents file . move file different directory don’t edit , thumbprint show. , thumbprints vital tool tracking reproducibility, change contents data changes.","code":"biota_data <- read_data(   compartment = \"biota\",    purpose = \"OSPAR\",                                  contaminants = \"test_data.csv\",    stations = \"station_dictionary.csv\",    data_format = \"ICES\", ) biota_data <- read_data(   compartment = \"biota\",    purpose = \"OSPAR\",                                  contaminants = \"test_data.csv\",    stations = \"station_dictionary.csv\",   data_dir = \"data_vignette\",   data_format = \"ICES\",   analysis_dir = \"analysis_vignette\" ) biota_data <- read_data(   compartment = \"biota\",    purpose = \"OSPAR\",                                  contaminants = \"test_data.csv\",    stations = \"station_dictionary.csv\",   data_dir = file.path(\"C:\", \"Users\", \"stuart\", \"OSPAR_vignette\", \"data\"),   data_format = \"ICES\",   analysis_dir = file.path(\"C:\", \"Users\", \"stuart\", \"somewhere_else\", \"assessment\"), )"},{"path":"http://osparcomm.github.io/HARSAT/articles/harsat.html","id":"getting-started","dir":"Articles","previous_headings":"","what":"Getting started","title":"Getting started","text":"now, assume familiar running basic R scripts . focus structure typical code looks like typical analysis.","code":""},{"path":"http://osparcomm.github.io/HARSAT/articles/harsat.html","id":"installing-harsat-from-github","dir":"Articles","previous_headings":"","what":"Installing harsat from GitHub","title":"Getting started","text":"install latest development version, use remotes package: Note: development repository marked private GitHub, need Personal Access Token (PAT) access . Follow instructions create Personal Access Token. ’ll short string, probably beginning ghp_. Put whole string auth_token parameter, install harsat package directly. Note: many functions currently cstm prefix. code originally developed, thought “contaminant time series modelling”, get cstm prefixes. removed near future.","code":"library(remotes) remotes::install_github(\"osparcomm/harsat\", auth_token = 'XXXX')"},{"path":"http://osparcomm.github.io/HARSAT/articles/harsat.html","id":"loading-the-code","dir":"Articles","previous_headings":"","what":"Loading the code","title":"Getting started","text":"Now, within R, can load library usual way","code":"library(harsat)"},{"path":"http://osparcomm.github.io/HARSAT/articles/harsat.html","id":"accessing-files","dir":"Articles","previous_headings":"","what":"Accessing files","title":"Getting started","text":"organize files . start current working directory. ’ll detect using R’s package, write variable working.directory.","code":"library(here) working.directory <- here()"},{"path":"http://osparcomm.github.io/HARSAT/articles/harsat.html","id":"reading-in-the-data","dir":"Articles","previous_headings":"","what":"Reading in the data","title":"Getting started","text":"first step read data ’ve got. go arguments. main arguments follows: compartment argument specifies whether ’re dealing biota assessment, sediment assessment, water assessment. purpose means can mirror OSPAR style assessment, HELCOM style assessment, AMAP-style assessment, means can basically tailor idea code sufficiently flexible can lot tailoring suit needs. contaminants data file chemical measurements . stations station file directly related station dictionary get ICES. QA quality assurance file – deprecated disappear. info_files reference tables – come back . reads three data sets, stage. get point, can look data want , anything else need data proceeding. Essentially files come point unchanged files reading . basically just reading data setting things . point might want whole lot ad hoc corrections data, done OSPAR estimates.","code":"biota_data <- read_data(   compartment = \"biota\",    purpose = \"OSPAR\",                                  contaminants = \"test_data.csv\",    stations = \"station_dictionary.csv\",    QA = \"quality_assurance.csv\",   data_dir = file.path(working.directory, \"data\", \"example_simple_OSPAR\"),   data_format = \"ICES_old\",   info_files = list(     determinand = \"determinand_simple_OSPAR.csv\",      thresholds = \"thresholds_biota_simple_OSPAR.csv\"   ),   info_dir = file.path(working.directory, \"information\"),    extraction = \"2022/01/11\",   max_year = 2020L ) #> Reading station dictionary from: #>  '/Users/stuart/git/HARSAT/data/example_simple_OSPAR/station_dictionary.csv' #>  #> Reading contaminant and biological effects data from: #>  '/Users/stuart/git/HARSAT/data/example_simple_OSPAR/test_data.csv' #>  #> Reading QA data from '/Users/stuart/git/HARSAT/data/example_simple_OSPAR/quality_assurance.csv'"},{"path":"http://osparcomm.github.io/HARSAT/articles/harsat.html","id":"tidying-the-data","dir":"Articles","previous_headings":"","what":"Tidying the data","title":"Getting started","text":"next step clean data prepare analysis. step tidies data structures ’ve got . filtering get data form want say, OSPAR assessment HELCOM assessment. also streamlines data files. may generate warnings. example, ’re cleaning station dictionary, ’ve may find issues duplicate stations. Similarly, comes cleaning contaminant biological effects data, ’ve may find data stations unrecognized station dictionary. Sometimes ’s fine sometimes ’s . Warnings supported output files allow come look see values affected, can go check detail. point, ’ve still done anything datasets.","code":"biota_data <- ctsm_tidy_data(biota_data) #>  #> Oddities will be written to 'oddities/biota' with previous oddities backed up to #>  'oddities/biota_backup' #>  #> Cleaning station dictionary #>    Duplicate stations - first one selected: see duplicate_stations.csv #>  #> Cleaning contaminant and biological effects data #>    Submitted.station unrecognised by dictionary: see stations_unrecognised.csv #>    Dropping data with no stations"},{"path":"http://osparcomm.github.io/HARSAT/articles/harsat.html","id":"create-time-series","dir":"Articles","previous_headings":"","what":"Create time series","title":"Getting started","text":"Now can group data time series. means identifying data points belong time series, set structure allows us assessments. various different ways can specify determinants actually want assess. case, determinands parameter specifies cadmium, CP153, CB153, HBCD, HBCDA, HBCDG, biological metabolites. various arguments allow control just data manipulated.","code":"biota_timeSeries <- ctsm_create_timeSeries(   biota_data,   determinands = c(\"CD\", \"CB153\", \"HBCD\",\"HBCDA\", \"HBCDG\", \"PYR1OH\"),   determinands.control = list(     HBCD = list(det = c(\"HBCDA\", \"HBCDB\", \"HBCDG\"), action = \"sum\"),     \"LIPIDWT%\" = list(det = c(\"EXLIP%\", \"FATWT%\"), action = \"bespoke\")   ),   get_basis = get_basis_biota_OSPAR ) #>  #> Oddities will be written to 'oddities/biota' with previous oddities backed up to #>  'oddities/biota_backup' #>  #> Cleaning data #>    Dropping stations with no data between 2015 and 2020  #>    Dropping samples with only auxiliary variables #>    Unexpected or missing values for 'matrix': see matrix_queries.csv #>    Unexpected or missing values for 'basis': see basis_queries.csv #>    Bile metabolite units changed from 'ng/g' to 'ng/ml' and from 'ug/kg' to 'ug/l' #>    Replicate measurements, only first retained: see replicate_measurements.csv #>    Limit of quantification less than limit of detection: see limits_inconsistent.csv #>    Detection limit higher than data: see detection_limit_high.csv #>    Data submitted as HBCDA, HBCDB, HBCDG summed to give HBCD #>    Data submitted as EXLIP% or FATWT% relabelled as LIPIDWT%  #>  #> Creating time series data #>    Converting data to appropriate basis for statistical analysis #>    Losing 32 out of 392 records in basis conversion due to missing, censored #>    or zero drywt or lipidwt values. #>    Dropping bivalve and gastropod contaminant data collected during the #>     spawning season, which is taken to be the following months: #>     April, May, June, July  #>    Dropping groups of compounds / stations with no data between 2015 and 2020"},{"path":"http://osparcomm.github.io/HARSAT/articles/harsat.html","id":"assessment","dir":"Articles","previous_headings":"","what":"Assessment","title":"Getting started","text":"next next stage assessment. ’ve created time series object, pass call. say thresholds ’re going use assessment options can put . just run. can see tells time series ’re actually assessing progresses. gives idea many cups tea can drink ’s finished. various little warnings: ones nothing worry . can check everything converged.","code":"biota_assessment <- run_assessment(   biota_timeSeries,   AC = c(\"BAC\", \"EAC\", \"EQS\", \"HQS\") ) #>  #> assessing series:  station_code 11461; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 11461; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 12156; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 12164; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 12164; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1235; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1235; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 1235; determinand HBCD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1235; determinand HBCDA; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1235; determinand HBCDG; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 13059; determinand CB153; species Spisula solida; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 13059; determinand CD; species Spisula solida; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 1345; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1345; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 1345; determinand HBCD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1345; determinand HBCDA; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1345; determinand HBCDG; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand HBCD; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand HBCDA; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1381; determinand HBCDG; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1388; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 1388; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 2717; determinand PYR1OH; species Limanda limanda; matrix BI; method_analysis HPLC-FD; unit ng/ml  #>  #> assessing series:  station_code 3282; determinand CB153; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3282; determinand CD; species Crassostrea gigas; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3433; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3433; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3441; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 3441; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg #> boundary (singular) fit: see help('isSingular') #> boundary (singular) fit: see help('isSingular') #>  #> assessing series:  station_code 7132; determinand CB153; species Mytilus edulis; matrix SB; basis D; unit ug/kg  #>  #> assessing series:  station_code 7132; determinand CD; species Mytilus edulis; matrix SB; basis D; unit ug/kg check_convergence_lmm(biota_assessment$assessment) #> [1] 0"},{"path":"http://osparcomm.github.io/HARSAT/articles/harsat.html","id":"reporting","dir":"Articles","previous_headings":"","what":"Reporting","title":"Getting started","text":"can get summary table results. want direcrory can put . harsat won’t create directory ’s nothing , let’s make new directory, ./output/tutorial, put full path summary.dir, can tell harsat write . Next, set variables manage display. can generate summary proper. summary file familiar involved OSPAR HELCOM assessments. summary files information time series, time series represents (first set columns), followed statistical results, p values, summary values number years data set, starts finishes. towards end, ’ve got comparisons various different threshold values.","code":"summary.dir <- file.path(working.directory, \"output\", \"tutorial\")  if (!dir.exists(summary.dir)) {   dir.create(summary.dir, recursive = TRUE) } webGroups <- list(   levels = c(\"Metals\", \"Metabolites\", \"Organobromines\", \"Chlorobiphenyls\"),     labels = c(     \"Metals\", \"PAH metabolites\", \"Organobromines\",  \"Polychlorinated biphenyls\"   ) )  classColour <- list(   below = c(     \"BAC\" = \"blue\",      \"EAC\" = \"green\",      \"EQS\" = \"green\",     \"HQS\" = \"green\"   ),   above = c(     \"BAC\" = \"orange\",      \"EAC\" = \"red\",      \"EQS\" = \"red\",     \"HQS\" = \"red\"   ),    none = \"black\" ) write_summary_table(   biota_assessment,    determinandGroups = webGroups,   classColour = classColour,   collapse_AC = list(EAC = c(\"EAC\", \"EQS\")),   output_dir = summary.dir  )"},{"path":"http://osparcomm.github.io/HARSAT/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rob Fryer. Author. Leszek Kaliciak. Author. Scottish Government. Funder, author. AmbieSense Ltd. Copyright holder, maintainer, author. Helsinki Commission (HELCOM). Copyright holder, funder, contributor. Arctic Monitoring Assessment Programme (AMAP). Copyright holder, funder, contributor. OSPAR Commission (OSPAR). Copyright holder, funder, contributor. International Council Exploration Sea (ICES). Copyright holder, author.","code":""},{"path":"http://osparcomm.github.io/HARSAT/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fryer R, Kaliciak L, Scottish Government, AmbieSense Ltd, International Council Exploration Sea (ICES) (2023). harsat: Harmonized Regional Seas Assessment Tool. https://github.com/osparcomm/HARSAT, https://osparcomm.github.io/HARSAT/.","code":"@Manual{,   title = {harsat: Harmonized Regional Seas Assessment Tool},   author = {Rob Fryer and Leszek Kaliciak and {Scottish Government} and {AmbieSense Ltd} and {International Council for the Exploration of the Sea (ICES)}},   year = {2023},   note = {https://github.com/osparcomm/HARSAT, https://osparcomm.github.io/HARSAT/}, }"},{"path":"http://osparcomm.github.io/HARSAT/index.html","id":"harsat","dir":"","previous_headings":"","what":"Harmonized Regional Seas Assessment Tool","title":"Harmonized Regional Seas Assessment Tool","text":"Requirements: R programming language version 4.2.1 RStudio Integrated Development Environment version 2022.07.1 Build 554 Additional R packages come standard RStudio installation. installed, either using RStudio GUI command install.packages e.g. install.packages(\"lme4\"): tidyverse version 2.0.0 dplyr lubridate stringr tibble tidyr sf lme4 mgcv mvtnorm numDeriv optimx pbapply parallel flexsurv following R packages need installed run HELCOM example: rmarkdown htmlwidgets File -> New Project RStudio create new project. File -> New Project -> Version Control -> GIT -> https://github.com/osparcomm/HARSAT clone repository. example datasets can run basic directory structure. following directories manually created: data R information output example scripts currently use subfolders within data output folders example_external_data example_HELCOM example_simple_OSPAR example_external_data example_HELCOM example_simple_OSPAR data output can go anywhere. Running code create directory called oddities data might comply reporting requirements posted (warnings errors).","code":""},{"path":"http://osparcomm.github.io/HARSAT/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Harmonized Regional Seas Assessment Tool","text":"can install development version harsat GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"osparcomm/HARSAT\")"},{"path":"http://osparcomm.github.io/HARSAT/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Harmonized Regional Seas Assessment Tool","text":"basic example shows solve common problem: following figures bit date: Figure 1. Required Project File Structure OSPAR dataset. Figure 2. Required Project File Structure HELCOM dataset. R functions GitHub code repository moved R, csv files reference tables go ‘information’. recommended R files examples, data output directories (project) directory e.g. HARSAT HARSAT HARSAT2022.r although one can adjust path argument ctsm_read_data ctsm.summary.table. ‘functions’ ‘information’ directories can anywhere (although recommended got directory), function_path variable (top OSPAR 2022.r) pointing former. Data required OSPAR: Figure 3. OSPAR data. Data required HELCOM: Figure 4. HELCOM data. HELCOM dataset requires additional R files work, different reference tables ‘assessment criteria biota.csv’ ‘assessment criteria sediment.csv’. HELCOM also requires different information functions repository different version HELCOM specific functions (‘information functions v2_68.r’). Figure 5. Additional R files required HELCOM dataset.","code":"library(harsat) ## basic example code"},{"path":"http://osparcomm.github.io/HARSAT/reference/add_stations.html","id":null,"dir":"Reference","previous_headings":"","what":"Add stations to contaminant data from an ICES extraction — add_stations","title":"Add stations to contaminant data from an ICES extraction — add_stations","text":"Adds station name station code contaminant data ICES extraction. done either matching station names submitted data station dictionary, matching sample coordinates station dictionary, combination .","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/add_stations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add stations to contaminant data from an ICES extraction — add_stations","text":"","code":"add_stations(data, stations, info)"},{"path":"http://osparcomm.github.io/HARSAT/reference/add_stations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add stations to contaminant data from an ICES extraction — add_stations","text":"data data frame contaminant data ICES extraction stations data frame ICES station dictionary info HARSAT information list must contain elements purpose, compartment, add_stations. latter list control parameters supplied control_default control_modify control station matching achieved. See details. compartment string: \"biota\", \"sediment\" \"water\"","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/add_stations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add stations to contaminant data from an ICES extraction — add_stations","text":"data frame containing contaminant data augmented variables containing station code station name","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/add_stations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Add stations to contaminant data from an ICES extraction — add_stations","text":"info$add_stations list control parameters modify station matching process: method: string specifying whether stations matched \"name\", \"coordinates\", \"\". info$purpose \"custom\", method restricted either \"name\" (default) \"coordinates\". info$purpose \"OSPAR\", \"HELCOM\" \"AMAP\", method set \"\" default stations matched name coordinates according rules specified OSPAR, HELCOM AMAP data providers. Specifically, stations matched name Denmark, France (biota water - years; sediment 2009 onwards), Ireland, Norway, Portugal, Spain (2005 onwards), Sweden, Netherlands (2007 onwards), United Kingdom. stations matched coordinates. area: vector strings containing one \"OSPAR\", \"HELCOM\" \"AMAP\"; restricts stations corresponding convention area(s); NULL matches stations station dictionary datatype: logical specifying whether stations restricted appropriate datatype. TRUE, contaminant measurement biota (example) matched stations station_datatype containing string \"CF\". Similarly, biological effect measurement biota matched stations station_datatype containing string \"EF\" temporal: logical TRUE indicating stations restricted station_purpm containing string \"T\" governance_type: string: \"none\", \"data\", \"stations\" \"\". \"none\" means data station governance ignored. \"data\" means matching restricted data governance station governance; example governance_id == c(\"OSPAR\", \"AMAP\"), data matched station one is_ospar_monitoring is_amap_monitoring TRUE, stations considered regardless station governance. \"stations\" mean matching restricted station governance data governance; example governance_id == c(\"OSPAR\", \"AMAP\"), stations restricted station_programgovernance contains either \"OSPAR\" \"AMAP\", data considered regardless data governance. uses data station governance. governance_id contains single value, matching strict. However, governance_id contains multiple values, matching complicated. example, governance_id == c(\"OSPAR\", \"AMAP\"), measurements is_ospar_monitoring == TRUE \"is_amap_monitoring == FALSE\" matched stations station_programgovernance contains \"OSPAR\"; measurements is_ospar_monitoring == FALSEandis_amap_monitoring == TRUEare matched stations wherestation_programgovernancecontains\"AMAP\"; measurements is_ospar_monitoring == TRUEandis_amap_monitoring == TRUEare matched stations wherestation_programgovernancecontains either\"OSPAR\"\"AMAP\"`. governance_id: vector strings containing one \"OSPAR\", \"HELCOM\" \"AMAP\". grouping: logical TRUE indicating stations grouped meta-stations specified station_asmtmimeparent station dictionary. Defaults FALSE apart info$purpose == \"OSPAR\". check_coordinates: logical TRUE indicating , stations matched name, sample coordinates must also within station geometry. implemented yet, defaults ot FALSE.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/check_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Check whether the assessments have converged — check_assessment","title":"Check whether the assessments have converged — check_assessment","text":"Checks whether assessments HARSAT assessment object converged. Currently detailed checks models normal lognormal errors (chemical timeseries biological effects). checks whether: fixed effect estimates away bounds random effect estimates lower upper bounds; can course equal zero standard errors present model predictions fixed effects estimates standard errors fixed effects estimates realistic (small standard errors indicate problems numerical differencing used compute standard errors)","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/check_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check whether the assessments have converged — check_assessment","text":"","code":"check_assessment(assessment_ob, save_result = FALSE)"},{"path":"http://osparcomm.github.io/HARSAT/reference/check_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check whether the assessments have converged — check_assessment","text":"assessment_ob HARSAT assessment object resulting call ctsm_assessment save_result Saves identifiers timeseries converged; defaults FALSE. assessment done stages, output also identifies timeseries yet assessed","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/check_assessment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check whether the assessments have converged — check_assessment","text":"list two character vectors: not_converged identifies timeseries converged not_assessed identifies timeseries assessed","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/check_convergence_lmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks convergence of an assessment model — check_convergence_lmm","title":"Checks convergence of an assessment model — check_convergence_lmm","text":"Utilty function use within assess_lmm. Checks whether model converged. Currently checks assessments normal (lognormal) errors, considers whether: fixed effect estimates away bounds random effect estimates lower upper bounds; can course equal zero standard errors present model predictions fixed effects estimates standard errors fixed effects estimates unrealistically small; tolerance chosen much smaller seen typical OSPAR assessments converged Model fits based distributions assumed converged. checking needed future","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/check_convergence_lmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks convergence of an assessment model — check_convergence_lmm","text":"","code":"check_convergence_lmm(assessment, coeff_se_tol = 0.001)"},{"path":"http://osparcomm.github.io/HARSAT/reference/check_convergence_lmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks convergence of an assessment model — check_convergence_lmm","text":"assessment assessment assess_lmm coeff_se_tol tolerance checking whether standard errors fixed effects estimates unrealistically small; defaults 0.001","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/check_convergence_lmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Checks convergence of an assessment model — check_convergence_lmm","text":"integer: 0 indicates convergence, 1 indicates issue","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/convert_units.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts units, e.g., from mg/kg to ug/kg — convert_units","title":"Converts units, e.g., from mg/kg to ug/kg — convert_units","text":"Can accept non-standard units (e.g. biological effects) provided rows identical (case attempt made convert.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/convert_units.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts units, e.g., from mg/kg to ug/kg — convert_units","text":"","code":"convert_units(conc, from, to)"},{"path":"http://osparcomm.github.io/HARSAT/reference/convert_units.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts units, e.g., from mg/kg to ug/kg — convert_units","text":"conc value convert current units required units","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/create_timeseries.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a time series — create_timeseries","title":"Create a time series — create_timeseries","text":"Cleans data turns time series structures ready assessment","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/create_timeseries.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a time series — create_timeseries","text":"","code":"create_timeseries(   ctsm.obj,   determinands = ctsm_get_determinands(ctsm.obj$info),   determinands.control = NULL,   oddity_path = \"oddities\",   return_early = FALSE,   print_code_warnings = FALSE,   get_basis = get_basis_default,   normalise = FALSE,   normalise.control = list() )"},{"path":"http://osparcomm.github.io/HARSAT/reference/cstm.VDS.environment.html","id":null,"dir":"Reference","previous_headings":"","what":"Detects the environment from the call — cstm.VDS.environment","title":"Detects the environment from the call — cstm.VDS.environment","text":"utility function detects package environment. imported harsat package, returns package environment. Otherwise, returns global environment. can safely export functions result , example, setting cluster child processes parallel computation.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/cstm.VDS.environment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Detects the environment from the call — cstm.VDS.environment","text":"","code":"cstm.VDS.environment()"},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.cl.html","id":null,"dir":"Reference","previous_headings":"","what":"ctsm.VDS.cl — ctsm.VDS.cl","title":"ctsm.VDS.cl — ctsm.VDS.cl","text":"ctsm.VDS.cl","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.cl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ctsm.VDS.cl — ctsm.VDS.cl","text":"","code":"ctsm.VDS.cl(fit, nsim = 1000)"},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.index.opt.html","id":null,"dir":"Reference","previous_headings":"","what":"ctsm.VDS.index.opt — ctsm.VDS.index.opt","title":"ctsm.VDS.index.opt — ctsm.VDS.index.opt","text":"ctsm.VDS.index.opt","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.index.opt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ctsm.VDS.index.opt — ctsm.VDS.index.opt","text":"","code":"ctsm.VDS.index.opt(data, theta, refLevel, calc.vcov = FALSE)"},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.loglik.calc.html","id":null,"dir":"Reference","previous_headings":"","what":"ctsm.VDS.loglik.calc — ctsm.VDS.loglik.calc","title":"ctsm.VDS.loglik.calc — ctsm.VDS.loglik.calc","text":"ctsm.VDS.loglik.calc","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.loglik.calc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ctsm.VDS.loglik.calc — ctsm.VDS.loglik.calc","text":"","code":"ctsm.VDS.loglik.calc(   theta,   data,   index.theta,   minus.twice = FALSE,   cumulate = FALSE )"},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.loglik.calc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ctsm.VDS.loglik.calc — ctsm.VDS.loglik.calc","text":"cumulate boolean, whether use cumulative probabilities","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.p.calc.html","id":null,"dir":"Reference","previous_headings":"","what":"ctsm.VDS.p.calc — ctsm.VDS.p.calc","title":"ctsm.VDS.p.calc — ctsm.VDS.p.calc","text":"ctsm.VDS.p.calc","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.p.calc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ctsm.VDS.p.calc — ctsm.VDS.p.calc","text":"","code":"ctsm.VDS.p.calc(theta, cumulate = FALSE)"},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.p.calc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ctsm.VDS.p.calc — ctsm.VDS.p.calc","text":"cumulate boolean, whether use cumulative probabilities","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.varlist.html","id":null,"dir":"Reference","previous_headings":"","what":"ctsm.VDS.varlist — ctsm.VDS.varlist","title":"ctsm.VDS.varlist — ctsm.VDS.varlist","text":"list names functions values necessary export cluster prcesses parallel computation","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.varlist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ctsm.VDS.varlist — ctsm.VDS.varlist","text":"","code":"ctsm.VDS.varlist"},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm.VDS.varlist.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ctsm.VDS.varlist — ctsm.VDS.varlist","text":"object class character length 4.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm_TBT_convert.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert tin concentrations — ctsm_TBT_convert","title":"Convert tin concentrations — ctsm_TBT_convert","text":"Convert tin concentrations cation concentrations. Also change_unit moves units tin units conventional units","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm_TBT_convert.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert tin concentrations — ctsm_TBT_convert","text":"","code":"ctsm_TBT_convert(   data,   subset,   action,   from = c(\"tin\", \"cation\"),   convert_var = c(\"value\", \"limit_detection\", \"limit_quantification\", \"uncertainty\") )"},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm_get_determinands.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the determinands to be assessed — ctsm_get_determinands","title":"Get the determinands to be assessed — ctsm_get_determinands","text":"Gets determinands assessed determinand reference table.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm_get_determinands.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the determinands to be assessed — ctsm_get_determinands","text":"","code":"ctsm_get_determinands(info)"},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm_get_determinands.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the determinands to be assessed — ctsm_get_determinands","text":"info list least following two components: compartment One \"biota\", \"sediment\" \"water\" determinand data frame holding determinand reference table","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm_get_determinands.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the determinands to be assessed — ctsm_get_determinands","text":"character string containing determinands assessed. function fail error message determinands.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm_get_determinands.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the determinands to be assessed — ctsm_get_determinands","text":"determinands taken column biota_assess, sediment_assess water_assess determinand reference table (compartment given info$compartment). TRUE values determinands assessed.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm_get_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets data from the standard reference tables — ctsm_get_info","title":"Gets data from the standard reference tables — ctsm_get_info","text":"Gets data standard reference tables","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/ctsm_get_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets data from the standard reference tables — ctsm_get_info","text":"","code":"ctsm_get_info(   ref_table,   input,   output,   compartment = NULL,   na_action = c(\"fail\", \"input_ok\", \"output_ok\", \"ok\"),   info_type = NULL,   sep = \".\" )"},{"path":"http://osparcomm.github.io/HARSAT/reference/get_AC.html","id":null,"dir":"Reference","previous_headings":"","what":"Access function map — get_AC","title":"Access function map — get_AC","text":"Access function map","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/get_AC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Access function map — get_AC","text":"","code":"get_AC"},{"path":"http://osparcomm.github.io/HARSAT/reference/get_AC.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Access function map — get_AC","text":"object class list length 3.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/get_basis_biota_OSPAR.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the OSPAR biota target basis — get_basis_biota_OSPAR","title":"Gets the OSPAR biota target basis — get_basis_biota_OSPAR","text":"Gets OSPAR biota target basis","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/get_basis_biota_OSPAR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the OSPAR biota target basis — get_basis_biota_OSPAR","text":"","code":"get_basis_biota_OSPAR(data, info)"},{"path":"http://osparcomm.github.io/HARSAT/reference/get_station_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Get station code from station name — get_station_code","title":"Get station code from station name — get_station_code","text":"Gets station code corresponding station name country station dictionary. works one country time","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/get_station_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get station code from station name — get_station_code","text":"","code":"get_station_code(station_name, country, stations)"},{"path":"http://osparcomm.github.io/HARSAT/reference/harsat-package.html","id":null,"dir":"Reference","previous_headings":"","what":"harsat: Harmonized Regional Seas Assessment Tool — harsat-package","title":"harsat: Harmonized Regional Seas Assessment Tool — harsat-package","text":"Assessment concentrations hazardous substances biological effects marine environment. code supports periodic international assessments OSPAR, HELCOM AMAP also assessments individual users. Includes tools pre-processing data, statistical trend analysis comparison threshold values, post-processing archiving reporting.","code":""},{"path":[]},{"path":"http://osparcomm.github.io/HARSAT/reference/harsat-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"harsat: Harmonized Regional Seas Assessment Tool — harsat-package","text":"Maintainer: AmbieSense Ltd info@ambiesense.com [copyright holder] Authors: Rob Fryer rob.fryer@gov.scot Leszek Kaliciak leszek@ambiesense.com Scottish Government marinescotland@gov.scot [funder] International Council Exploration Sea (ICES) info@ices.dk [copyright holder] contributors: Helsinki Commission (HELCOM) secretariat@helcom.fi [copyright holder, funder, contributor] Arctic Monitoring Assessment Programme (AMAP) amap@amap.[copyright holder, funder, contributor] OSPAR Commission (OSPAR) secretariat@ospar.org [copyright holder, funder, contributor]","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/plot_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Graphical summaries of an assessment — plot_assessment","title":"Graphical summaries of an assessment — plot_assessment","text":"Generates series assessment plots raw data, annual indices, . plots exported either png pdf files.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/plot_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Graphical summaries of an assessment — plot_assessment","text":"","code":"plot_assessment(   assessment_obj,   subset = NULL,   output_dir = \".\",   file_type = c(\"data\", \"index\"),   file_format = c(\"png\", \"pdf\") )"},{"path":"http://osparcomm.github.io/HARSAT/reference/plot_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Graphical summaries of an assessment — plot_assessment","text":"assessment_obj assessment object resulting call run_assessment subset optional vector specifying timeseries plotted. expression evaluated timeSeries component assessment_obj; use 'series' identify individual timeseries. output_dir output directory assessment plots (possibly supplied using 'file.path'). default working directory. output directory must already exist. file_type Specifies whether plots show raw data ('file_type = \"data\"'), annual indices summarising data year ('file_type = \"index\"'), (default) whether two files produced time series, one raw data one annual indices. file_format Whether files png (default) pdf.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/plot_assessment.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Graphical summaries of an assessment — plot_assessment","text":"series png pdf files graphical summaries assessment. plots show fitted trends pointwise two-sided 90% confidence limits either raw data, indices summarising data year.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/read_contaminants.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads contaminant data — read_contaminants","title":"Reads contaminant data — read_contaminants","text":"Reads contaminant data","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/read_contaminants.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads contaminant data — read_contaminants","text":"","code":"read_contaminants(file, data_dir = \".\", info)"},{"path":"http://osparcomm.github.io/HARSAT/reference/read_contaminants.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads contaminant data — read_contaminants","text":"file file reference contaminant data. data_dir path directory holding contaminant data. Defaults working directory. info list containing least following two elements: compartment: \"biota\", \"sediment\" \"water\" data_format: \"ICES\" \"external\"","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/read_contaminants.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads contaminant data — read_contaminants","text":"data frame containing contaminant data.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/read_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Read HARSAT data — read_data","title":"Read HARSAT data — read_data","text":"Reads contaminant data, station dictionary reference table. Also allows user set various control parameters.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/read_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read HARSAT data — read_data","text":"","code":"read_data(   compartment = c(\"biota\", \"sediment\", \"water\"),   purpose = c(\"OSPAR\", \"HELCOM\", \"AMAP\", \"custom\"),   contaminants,   stations,   QA,   data_dir = \".\",   data_format = c(\"ICES\", \"external\", \"ICES_old\", \"ICES_new\"),   info_files = list(),   info_dir = \".\",   extraction = NULL,   max_year = NULL,   oddity_dir = \"oddities\",   control = list() )"},{"path":"http://osparcomm.github.io/HARSAT/reference/read_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read HARSAT data — read_data","text":"compartment string: \"biota\", \"sediment\" \"water\" purpose string specifying whether use default set \"OSPAR\", \"HELCOM\", \"AMAP\" use customised setup \"custom\" contaminants file reference contaminant data stations file reference station data QA file reference QA data data_dir directory data files can found (sometimes supplied using 'file.path'). Defaults \".\"; .e. working directory. data_format string specifying whether data extracted ICES webservice (\"ICES\" - default) simplified format designed data sources (\"external\"). values \"ICES_old\" \"ICES_new\" deprecated. info_files list files specifying reference tables override defaults. See examples. info_dir directory reference tables can found (sometimes supplied using 'file.path'). Defaults \".\"; .e. working directory extraction date saying extraction made. Optional. provided according ISO 8601; example, 29 February 2024 supplied \"2024-02-29\". contaminant data extracted ICES webservice download file name changed, extraction data taken contaminant file name. max_year integer giving last monitoring year included assessment. Data monitoring years max_year deleted. specified max_year taken last monitoring year contaminant data file. oddity_dir directory 'oddities' written (sometimes supplied using 'file.path'). directory (subdirectories) created already exist. control list control parameters override default values used run assessment. include reporting window; way data matched stations following ICES extraction; information reporting regions, . See Details.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/read_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read HARSAT data — read_data","text":"list following components: call function call. info list containing reference tables control parameters. data data frame containing contaminant (effects) data. (virtually) identical input data file. However, extra empty columns probably added , ICES data, columns renamed. ICES data, also extra column .keep, logical indicating whether record retained previous ICES extraction protocol. example, .keep FALSE vflag entry \"S\" suspect. Records .keep FALSE deleted later tidy_data. stations","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/read_stations.html","id":null,"dir":"Reference","previous_headings":"","what":"Reads station dictionary — read_stations","title":"Reads station dictionary — read_stations","text":"Reads station dictionary","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/read_stations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reads station dictionary — read_stations","text":"","code":"read_stations(file, data_dir = \".\", info)"},{"path":"http://osparcomm.github.io/HARSAT/reference/read_stations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reads station dictionary — read_stations","text":"file file reference station dictionary. data_dir path directory holding station dictionary. Defaults working directory. info list containing least following two elements: compartment: \"biota\", \"sediment\" \"water\" data_format: \"ICES\" \"external\"","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/read_stations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reads station dictionary — read_stations","text":"data frame containing station dictionary.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/run_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Assess timeseries for trends and status — run_assessment","title":"Assess timeseries for trends and status — run_assessment","text":"Fits model timeseries, test temporal trend compare thresholds. Need add lot details.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/run_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assess timeseries for trends and status — run_assessment","text":"","code":"run_assessment(   ctsm_ob,   subset = NULL,   AC = NULL,   get_AC_fn = NULL,   recent_trend = 20L,   parallel = FALSE,   ... )"},{"path":"http://osparcomm.github.io/HARSAT/reference/run_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assess timeseries for trends and status — run_assessment","text":"ctsm_ob HARSAT object resulting call create_timeSeries subset optional vector specifying timeseries assessed. Might used assessment done chunks size, refitting timeseries model converged. expression evaluated timeSeries component ctsm_ob; use 'series' identify individual timeseries. AC character vector identifying thresholds used status assessments. threshold reference table. Defaults NULL; .e. thresholds used. get_AC_fn optional function overrides get_AC_default. See details (need written). recent_trend integer giving number years used assessment recent trends. example, value 20 (default) consider trends last twenty year. parallel logical determines whether use parallel computation; default = FALSE. ... Extra arguments passed assessment_engine.  See details (need written).","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/tidy_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy the data — tidy_data","title":"Tidy the data — tidy_data","text":"Reduces size extraction removing redundant variables. ad-hoc changes usually made read_data simplify_data. output correct format create_timeSeries.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/tidy_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy the data — tidy_data","text":"","code":"tidy_data(ctsm_obj)"},{"path":"http://osparcomm.github.io/HARSAT/reference/tidy_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy the data — tidy_data","text":"ctsm_obj","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/update_assessment.html","id":null,"dir":"Reference","previous_headings":"","what":"Update timeseries assessments — update_assessment","title":"Update timeseries assessments — update_assessment","text":"Refits models particular timeseries, fits new models assessment done chunks.","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/update_assessment.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update timeseries assessments — update_assessment","text":"","code":"update_assessment(ctsm_ob, subset = NULL, parallel = FALSE, ...)"},{"path":"http://osparcomm.github.io/HARSAT/reference/update_assessment.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update timeseries assessments — update_assessment","text":"ctsm_ob HARSAT object resulting call run_assessment subset vector specifying timeseries assessements updated fit first time. expression evaluated timeSeries component ctsm_ob; use 'series' identify individual timeseries. parallel logical determines whether use parallel computation; default = FALSE. ... Extra arguments passed assessment_engine.  See details (need written).","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/write_summary_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Write assessment summary to a csv file — write_summary_table","title":"Write assessment summary to a csv file — write_summary_table","text":"Creates data frame summarising assessment time series writes csv file. summary includes: meta-data monitoring location number years data time series fitted values last monitoring year associated upper one-sided 95% confidence limits trend assessments (p-values trend estimates) status assessments (thresholds (optionally) symbology summarising trend (shape) status (colour) time series","code":""},{"path":"http://osparcomm.github.io/HARSAT/reference/write_summary_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write assessment summary to a csv file — write_summary_table","text":"","code":"write_summary_table(   assessment_obj,   output_file = NULL,   output_dir = \".\",   export = TRUE,   determinandGroups = NULL,   classColour = NULL,   collapse_AC = NULL )"},{"path":"http://osparcomm.github.io/HARSAT/reference/write_summary_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write assessment summary to a csv file — write_summary_table","text":"assessment_obj assessment object resulting call run_assessment. output_file name output csv file. using NULL, file called biota_summary.csv, sediment_summary.csv water_summary.csv appropriate. default file written working directory. file name provided, path output file can also provided (e.g. using file.path). output_dir option can also used specify output file directory. output_dir output directory output_file. default working directory. file path provided output_file, appended output_dir. resulting output directory must already exist. export Logical. TRUE (default) writes summary table csv file. FALSE returns summary table R object (write csv file). collapse_AC","code":""}]
